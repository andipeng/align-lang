{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77db741a-d9b8-4cd4-acdd-c2477e5e6a1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vima_bench.env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     42\u001b[0m lang_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvima_bench\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvima_bench\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PARTITION_TO_SPECS\n",
      "File \u001b[0;32m~/Dropbox (MIT)/Code/projects/align-lang/VimaBench/vima_bench/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VIMAEnvBase\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALL_TASKS, ALL_PARTITIONS, PARTITION_TO_SPECS\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptRenderer, GUIRecorder\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vima_bench.env'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import io\n",
    "import json\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import distributions as pyd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode - o\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "lang_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "import vima_bench\n",
    "from vima_bench import PARTITION_TO_SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f9ffc-1863-416a-887e-44f008b71c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "                \n",
    "# helper mlp init function\n",
    "def mlp(input_dim, output_dim, hidden_dim, hidden_depth, output_mod=None):\n",
    "    if hidden_depth == 0:\n",
    "        mods = [nn.Linear(input_dim, output_dim)]\n",
    "    else:\n",
    "        mods = [nn.Linear(input_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        for i in range(hidden_depth - 1):\n",
    "            mods += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        mods.append(nn.Linear(hidden_dim, output_dim))\n",
    "    if output_mod is not None:\n",
    "        mods.append(output_mod)\n",
    "    trunk = nn.Sequential(*mods)\n",
    "    return trunk\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.size(0), -1)\n",
    "\n",
    "# CNN policy\n",
    "class GCBCPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, action_dim, hidden_size, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,72)=>(b_size,32,8,17)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,17)=>(b_size,64,3,7)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(), #(b_size,64,3,7)=>(b_size,32,1,5)=>(b_size,32*1*5)\n",
    "            nn.Linear(32*1*5, hidden_size)#, nn.LeakyReLU(inplace=True), nn.BatchNorm1d(32), #(b_size,32*1*5)=>(b_size,action_dim)\n",
    "        )\n",
    "        self.policy = mlp(hidden_size+384, action_dim, hidden_dim=100, hidden_depth=1)\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, state, goal):\n",
    "        state = state/255.0 # process image + switch channels\n",
    "        state = state.permute(0,3,1,2)\n",
    "        state_embed = self.cnn(state)\n",
    "        \n",
    "        gc_embed = torch.cat([state_embed, goal], dim=1)\n",
    "        action = self.policy(gc_embed)\n",
    "        return action\n",
    "\n",
    "class BCPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, action_dim, hidden_size, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,72)=>(b_size,32,8,17)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,17)=>(b_size,64,3,7)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(), #(b_size,64,3,7)=>(b_size,32,1,5)=>(b_size,32*1*5)\n",
    "            nn.Linear(32*1*5, action_dim)#, nn.LeakyReLU(inplace=True), nn.BatchNorm1d(32), #(b_size,32*1*5)=>(b_size,action_dim)\n",
    "        )\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = state/255.0 # process image + switch channels\n",
    "        state = state.permute(0,3,1,2)\n",
    "        action = self.cnn(state)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07cbd67-71e4-4c60-8662-070077913cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsize_obs(obs):\n",
    "    cv2.imwrite('temp.jpg', obs)\n",
    "    img = cv2.imread('temp.jpg')\n",
    "    downsized_obs = cv2.resize(img, dsize=(72, 36), interpolation=cv2.INTER_CUBIC)\n",
    "    return downsized_obs\n",
    "\n",
    "def flatten_act(action):\n",
    "    return np.concatenate(list(action.values())).ravel()\n",
    "\n",
    "# reconstructs actions for simulator\n",
    "def reconstruct_act(action):\n",
    "    reconst_action = {}\n",
    "    reconst_action['pose0_position'] = np.array(action[0:2])\n",
    "    reconst_action['pose0_rotation'] = np.array(action[2:6])\n",
    "    reconst_action['pose1_position'] = np.array(action[6:8])\n",
    "    reconst_action['pose1_rotation'] = np.array(action[8:12])\n",
    "    reconst_action = {\n",
    "        k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "        for k, v in reconst_action.items()\n",
    "    }\n",
    "    return reconst_action\n",
    "\n",
    "def remove_obj(segm, obs, remove_obj):\n",
    "    #if remove_obj == 'arm':\n",
    "    #    segm = (segm == 2).astype(int)\n",
    "    if remove_obj == 'base':\n",
    "        segm = (segm == 5).astype(int)\n",
    "    elif remove_obj == 'dragged':\n",
    "        segm = (segm == 6).astype(int)\n",
    "    elif remove_obj == 'distractor':\n",
    "        segm = (segm == 7).astype(int)\n",
    "    segm = np.atleast_3d(segm)\n",
    "    \n",
    "    for height in range(128):\n",
    "        for width in range(256):\n",
    "            if segm[height, width] == 1:\n",
    "                obs[height, width] = 47\n",
    "    return obs\n",
    "\n",
    "def compare_actions(actions, gt_action):\n",
    "    comparisons = []\n",
    "    for action in actions:\n",
    "        comparisons.append(np.linalg.norm(gt_action - action[[0,1,6,7]],ord=2))\n",
    "    return comparisons\n",
    "\n",
    "# generates random trajs within specified constraints\n",
    "def gen_trajs(env, num_trajs, task_name, task_kwargs, goal):\n",
    "    trajs = []\n",
    "    task = env.task\n",
    "    oracle_fn = task.oracle(env)\n",
    "    for traj in tqdm(range(num_trajs)):\n",
    "        traj = {'obs': [],'acts': [], 'goals':[], 'meta': []}\n",
    "        obs = env.reset()\n",
    "        traj['meta'] = env.meta_info\n",
    "        obj_type = env.meta_info['obj_id_to_info'][6]['obj_name']\n",
    "        goal_embed = lang_model.encode(obj_type)\n",
    "        for step in range(1):\n",
    "            top_obs = obs['rgb']['top'] # extracts top down view only\n",
    "            top_obs = np.rollaxis(top_obs,0,3)\n",
    "            traj['obs'].append(downsize_obs(top_obs.copy()))\n",
    "            traj['goals'].append(goal_embed)\n",
    "            # prompt, prompt_assets = env.prompt, env.prompt_assets\n",
    "            oracle_action = oracle_fn.act(obs)\n",
    "            # clip action\n",
    "            oracle_action = {\n",
    "                k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "                for k, v in oracle_action.items()\n",
    "            }\n",
    "            traj['acts'].append(flatten_act(oracle_action))\n",
    "            obs, _, done, info = env.step(action=oracle_action, skip_oracle=False)\n",
    "        traj['obs'] = np.array(traj['obs'])\n",
    "        traj['acts'] = np.array(traj['acts'])\n",
    "        traj['goals'] = np.array(traj['goals'])\n",
    "        traj['meta'] = np.array(traj['meta'])\n",
    "        trajs.append(traj)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccfc2f6-2659-4640-b9d6-0a7546455ef9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vima_bench' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m      5\u001b[0m task_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpossible_dragged_obj\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpan\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpossible_dragged_obj_texture\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpossible_angles_of_rotation\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m45\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#task_kwargs = {'num_dragged_obj': 1,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     'num_base_obj': 1,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     'num_other_obj': 0,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     'possible_fourth_obj_texture': ['blue']}\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#record_gui=True, display_debug_window=True, hide_arm_rgb=False\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mvima_bench\u001b[49m\u001b[38;5;241m.\u001b[39mmake(task_name\u001b[38;5;241m=\u001b[39mtask_name,task_kwargs\u001b[38;5;241m=\u001b[39mtask_kwargs,hide_arm_rgb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m num_trajs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     27\u001b[0m trajs \u001b[38;5;241m=\u001b[39m gen_trajs(env\u001b[38;5;241m=\u001b[39menv, num_trajs\u001b[38;5;241m=\u001b[39mnum_trajs, task_name\u001b[38;5;241m=\u001b[39mtask_name, task_kwargs\u001b[38;5;241m=\u001b[39mtask_kwargs, goal\u001b[38;5;241m=\u001b[39mlang_embed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vima_bench' is not defined"
     ]
    }
   ],
   "source": [
    "lang_goal = 'bring me the bowl'\n",
    "lang_embed = lang_model.encode(lang_goal)\n",
    "\n",
    "task_name = 'rotate'\n",
    "task_kwargs = {'possible_dragged_obj' : ['pan'],\n",
    "               'possible_dragged_obj_texture' : ['red'],\n",
    "               'possible_angles_of_rotation' : ['45']}\n",
    "#task_kwargs = {'num_dragged_obj': 1,\n",
    "#     'num_base_obj': 1,\n",
    "#     'num_other_obj': 0,\n",
    "#     'dragged_obj_loc': [1],\n",
    "#     'base_obj_loc': [4],\n",
    "#     'third_obj_loc' : [1],\n",
    "#     'fourth_obj_loc' : [3],\n",
    "#     'possible_dragged_obj': ['block'],\n",
    "#     'possible_dragged_obj_texture': ['red'],\n",
    "#     'possible_base_obj': ['pan'],\n",
    "#     'possible_base_obj_texture': ['tiger'],\n",
    "#     'possible_third_obj': ['bowl'],\n",
    "#     'possible_third_obj_texture': ['blue'],\n",
    "#     'possible_fourth_obj': ['pentagon'],\n",
    "#     'possible_fourth_obj_texture': ['blue']}\n",
    "#record_gui=True, display_debug_window=True, hide_arm_rgb=False\n",
    "env = vima_bench.make(task_name=task_name,task_kwargs=task_kwargs,hide_arm_rgb=False)\n",
    "\n",
    "num_trajs = 10\n",
    "trajs = gen_trajs(env=env, num_trajs=num_trajs, task_name=task_name, task_kwargs=task_kwargs, goal=lang_embed)\n",
    "pickle.dump(trajs, open('trajs.pkl', 'wb'))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b88c2-3372-4b12-b64e-3b7d4cf43f4d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_tasks = len(trajs)\n",
    "\n",
    "act_size = trajs[0]['acts'][0].shape[0]\n",
    "hidden_size = 100\n",
    "\n",
    "#policy = GCBCPolicy(act_size, hidden_size)\n",
    "policy = BCPolicy(act_size, hidden_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde3ee5-ce6a-41eb-ac85-860781776e8f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 750\n",
    "batch_size = 10\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(policy.parameters()), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(trajs)))\n",
    "\n",
    "num_batches = len(idxs) // batch_size\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    np.random.shuffle(idxs)\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_idx = np.random.randint(len(trajs), size=(batch_size,)) # Indices of traj\n",
    "        t_idx_pertraj = np.random.randint(1, size=(batch_size,)) # Indices of timesteps in traj\n",
    "        t_states = np.concatenate([trajs[c_idx]['obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_goals = np.concatenate([trajs[c_idx]['goals'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_actions = np.concatenate([trajs[c_idx]['acts'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "   \n",
    "        t_states = torch.Tensor(t_states).float().to(device)\n",
    "        t_goals = torch.Tensor(t_goals).float().to(device)\n",
    "        t_actions = torch.Tensor(t_actions).float().to(device)\n",
    "        \n",
    "        #a_preds = policy(t_states, t_goals)\n",
    "        a_preds = policy(t_states)\n",
    "        loss = torch.mean(torch.linalg.norm(a_preds - t_actions, dim=-1)) # supervised learning loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "torch.save(policy, 'policy_gcbc.pt')\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1bd52a-f3e5-41d7-b327-cb9bf03e20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_goal = 'bring me the bowl'\n",
    "lang_embed = lang_model.encode(lang_goal)\n",
    "\n",
    "task_name = 'visual_manipulation'\n",
    "task_kwargs = {'num_dragged_obj': 1,\n",
    "     'num_base_obj': 1,\n",
    "     'num_other_obj': 0,\n",
    "     'dragged_obj_loc': [1],\n",
    "     'base_obj_loc': [4],\n",
    "     'third_obj_loc' : [1],\n",
    "     'fourth_obj_loc' : [3],\n",
    "     'possible_dragged_obj': ['block'],\n",
    "     'possible_dragged_obj_texture': ['red'],\n",
    "     'possible_base_obj': ['pan'],\n",
    "     'possible_base_obj_texture': ['tiger'],\n",
    "     'possible_third_obj': ['bowl'],\n",
    "     'possible_third_obj_texture': ['blue'],\n",
    "     'possible_fourth_obj': ['pentagon'],\n",
    "     'possible_fourth_obj_texture': ['blue']}\n",
    "record_cfg = {'save_video': True,\n",
    "     'save_video_path': './rollouts_gcbc/',\n",
    "     'view': 'front',\n",
    "     'fps': 18,\n",
    "     'video_height': 320,\n",
    "     'video_width': 368}\n",
    "# record_gui=True, display_debug_window=True, hide_arm_rgb=False\n",
    "env = vima_bench.make(task_name=task_name,task_kwargs=task_kwargs,hide_arm_rgb=False,record_cfg=record_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10160fc2-8e9d-4d65-8517-3421c5fae5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oracle = True\n",
    "\n",
    "if oracle:\n",
    "    task = env.task\n",
    "    oracle_fn = task.oracle(env)\n",
    "else:\n",
    "    policy = torch.load('policy_gcbc.pt')\n",
    "    policy.eval()\n",
    "\n",
    "obj_to_remove = None#['base']\n",
    "num_test_trajs = 1\n",
    "video = True\n",
    "\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.ylim(0.3, 0.7)\n",
    "\n",
    "successes = []\n",
    "\n",
    "rollouts = {'actions': [], 'action_starts': [],'action_ends': [], 'true_starts': [], 'true_ends': []}\n",
    "\n",
    "for i in tqdm(range(num_test_trajs)):\n",
    "    os.makedirs('rollouts_gcbc/' + str(i), exist_ok=True)\n",
    "    obs = env.reset()\n",
    "    obj_type = env.meta_info['obj_id_to_info'][6]['obj_name']\n",
    "    goal_embed = lang_model.encode(obj_type)\n",
    "    \n",
    "    if video:\n",
    "        video_name = str(i)\n",
    "        env.start_rec(video_name)\n",
    "    for step in range(1):\n",
    "        if oracle:\n",
    "            oracle_action = oracle_fn.act(obs)\n",
    "            # clip action\n",
    "            oracle_action = {\n",
    "                k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "                for k, v in oracle_action.items()\n",
    "            }\n",
    "            obs, _, done, info = env.step(action=oracle_action, skip_oracle=False)\n",
    "        \n",
    "        else:\n",
    "            segm = obs['segm']['top']\n",
    "            top_obs = obs['rgb']['top']\n",
    "            top_obs = np.rollaxis(top_obs,0,3)\n",
    "\n",
    "            if obj_to_remove is not None:\n",
    "                obj_removed = random.choice(obj_to_remove)\n",
    "                segm = obs['segm']['top']\n",
    "                top_obs = remove_obj(segm, top_obs, obj_removed)\n",
    "            first_obs = top_obs.copy()\n",
    "\n",
    "            im = Image.fromarray(top_obs)\n",
    "            im.save('rollouts_gcbc/'+str(i)+\"/\"+str(step)+'.jpg')\n",
    "            top_obs = downsize_obs(top_obs)\n",
    "            state = torch.Tensor(top_obs[None]).to(device)\n",
    "            goal = torch.Tensor(lang_embed[None]).to(device)\n",
    "            #action = policy(state,goal).cpu().detach().numpy()[0]\n",
    "            action = policy(state).cpu().detach().numpy()[0]\n",
    "            \n",
    "            rollouts['actions'].append(action)\n",
    "            rollouts['action_starts'].append(action[0:2].copy())\n",
    "            rollouts['action_ends'].append(action[6:8].copy())\n",
    "            obs, _, done, info = env.step(action=reconstruct_act(action), skip_oracle=False)\n",
    "            segm = obs['segm']['top']\n",
    "        \n",
    "        if done:\n",
    "            successes.append(1)\n",
    "        else:\n",
    "            successes.append(0)\n",
    "            \n",
    "    if video:\n",
    "        env.end_rec()\n",
    "        \n",
    "    top_obs = obs['rgb']['top']\n",
    "    top_obs = np.rollaxis(top_obs,0,3)\n",
    "    \n",
    "    if obj_to_remove is not None:\n",
    "        segm = obs['segm']['top']\n",
    "        top_obs = remove_obj(segm, top_obs, obj_removed)\n",
    "        \n",
    "    im = Image.fromarray(top_obs)\n",
    "    im.save('rollouts_gcbc/'+str(i)+\"/\"+str(step+1)+'.jpg')\n",
    "\n",
    "env.close()\n",
    "print(sum(successes)/len(successes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a376394-e37b-4926-a830-c574c6bf9f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.rollaxis(obs['rgb']['top'],0,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
