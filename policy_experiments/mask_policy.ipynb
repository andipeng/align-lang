{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f0d922-9122-492f-a425-7c41288cd5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Apr 20 2023 11:39:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 17 tasks loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import io\n",
    "import json\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import distributions as pyd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode - o\n",
    "\n",
    "import vima_bench\n",
    "from vima_bench import PARTITION_TO_SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54148dee-8459-4fc9-a5be-7187a452b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "# helper mlp init function\n",
    "def mlp(input_dim, output_dim, hidden_dim, hidden_depth, output_mod=None):\n",
    "    if hidden_depth == 0:\n",
    "        mods = [nn.Linear(input_dim, output_dim)]\n",
    "    else:\n",
    "        mods = [nn.Linear(input_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        for i in range(hidden_depth - 1):\n",
    "            mods += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        mods.append(nn.Linear(hidden_dim, output_dim))\n",
    "    if output_mod is not None:\n",
    "        mods.append(output_mod)\n",
    "    trunk = nn.Sequential(*mods)\n",
    "    return trunk\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.size(0), -1)\n",
    "\n",
    "# MLP policy\n",
    "class CNNPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, action_dim, hidden_size, output_mod=None):\n",
    "        super().__init__()\n",
    "        # cnn for processing rgb state\n",
    "        self.cnn_state = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,72)=>(b_size,32,8,17)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,17)=>(b_size,64,3,7)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(),#(b_size,64,3,7)=>(b_size,32,1,5)=>(b_size,32*1*5)\n",
    "            nn.Linear(32*1*5, hidden_size)\n",
    "        )\n",
    "        # cnn for processing abstract state/mask\n",
    "        self.mask = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,4,36,72)=>(b_size,32,8,17)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,17)=>(b_size,64,3,7)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(), #(b_size,64,3,7)=>(b_size,32,1,5)=>(b_size,32*1*5)\n",
    "            nn.Linear(32*1*5, hidden_size)#, nn.LeakyReLU(inplace=True), nn.BatchNorm1d(32), #(b_size,32*1*5)=>(b_size,action_dim)\n",
    "        )\n",
    "        self.policy = mlp(hidden_size*2, action_dim, hidden_dim=100, hidden_depth=1)\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, state, s_hat):\n",
    "        # state in RGB 0-255, mask in greyscale 0/1\n",
    "        state = state/255.0 # normalize image + switch channels\n",
    "        state = state.permute(0,3,1,2)\n",
    "        s_hat = s_hat.unsqueeze(1) # adds in dummy 1channel for abstract state\n",
    "        \n",
    "        state_embed = self.cnn_state(state)\n",
    "        s_hat_embed = self.mask(s_hat)\n",
    "        s_concat = torch.cat([state_embed, s_hat_embed], dim=1)\n",
    "        \n",
    "        action = self.policy(s_concat)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1a71a4-7140-4929-8657-f63e6164bf9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downsize_obs(obs):\n",
    "    cv2.imwrite('temp.jpg', obs)\n",
    "    img = cv2.imread('temp.jpg')\n",
    "    downsized_obs = cv2.resize(img, dsize=(72, 36), interpolation=cv2.INTER_CUBIC)\n",
    "    return downsized_obs\n",
    "\n",
    "def downsize_segm(segm):\n",
    "    downsized_obs = cv2.resize(segm, dsize=(72, 36))\n",
    "    downsized_obs = (downsized_obs != 0).astype('float32')\n",
    "    return downsized_obs\n",
    "\n",
    "def flatten_act(action):\n",
    "    return np.concatenate(list(action.values())).ravel()\n",
    "\n",
    "# reconstructs actions for simulator\n",
    "def reconstruct_act(action):\n",
    "    reconst_action = {}\n",
    "    reconst_action['pose0_position'] = np.array(action[0:2])\n",
    "    reconst_action['pose0_rotation'] = np.array(action[2:6])\n",
    "    reconst_action['pose1_position'] = np.array(action[6:8])\n",
    "    reconst_action['pose1_rotation'] = np.array(action[8:12])\n",
    "    reconst_action = {\n",
    "        k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "        for k, v in reconst_action.items()\n",
    "    }\n",
    "    return reconst_action\n",
    "\n",
    "def remove_obj(segm, obs, remove_obj):\n",
    "    #if remove_obj == 'arm':\n",
    "    #    segm = (segm == 2).astype(int)\n",
    "    if remove_obj == 'base':\n",
    "        segm = (segm == 5).astype(int)\n",
    "    elif remove_obj == 'dragged':\n",
    "        segm = (segm == 6).astype(int)\n",
    "    elif remove_obj == 'distractor':\n",
    "        segm = (segm == 7).astype(int)\n",
    "    segm = np.atleast_3d(segm)\n",
    "    \n",
    "    for height in range(128):\n",
    "        for width in range(256):\n",
    "            if segm[height, width] == 1:\n",
    "                obs[height, width] = 47\n",
    "    return obs\n",
    "\n",
    "# removes everything but target object\n",
    "def find_target(segm):\n",
    "    target_obs = (segm == 6).astype('float32')\n",
    "    return target_obs\n",
    "\n",
    "def compare_actions(actions, gt_action):\n",
    "    comparisons = []\n",
    "    for action in actions:\n",
    "        comparisons.append(np.linalg.norm(gt_action - action[[0,1,6,7]],ord=2))\n",
    "    return comparisons\n",
    "\n",
    "# generates random trajs within specified constraints\n",
    "def gen_trajs(env, num_trajs, task_name, task_kwargs):\n",
    "    trajs = []\n",
    "    task = env.task\n",
    "    oracle_fn = task.oracle(env)\n",
    "    for traj in tqdm(range(num_trajs)):\n",
    "        traj = {'obs': [], 'target_obs': [], 'acts': [], 'meta': []}\n",
    "        obs = env.reset()\n",
    "        traj['meta'] = env.meta_info\n",
    "        for step in range(1):\n",
    "            top_obs = obs['rgb']['top'] # extracts top down view only\n",
    "            top_obs = np.rollaxis(top_obs,0,3)\n",
    "            traj['obs'].append(downsize_obs(top_obs.copy()))\n",
    "            top_segm = obs['segm']['top']\n",
    "            top_segm = find_target(top_segm)\n",
    "            traj['target_obs'].append(downsize_segm(top_segm.copy()))\n",
    "            # prompt, prompt_assets = env.prompt, env.prompt_assets\n",
    "            oracle_action = oracle_fn.act(obs)\n",
    "            # clip action\n",
    "            oracle_action = {\n",
    "                k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "                for k, v in oracle_action.items()\n",
    "            }\n",
    "            traj['acts'].append(flatten_act(oracle_action))\n",
    "            obs, _, done, info = env.step(action=oracle_action, skip_oracle=False)\n",
    "        traj['obs'] = np.array(traj['obs'])\n",
    "        traj['target_obs'] = np.array(traj['target_obs'])\n",
    "        traj['acts'] = np.array(traj['acts'])\n",
    "        traj['meta'] = np.array(traj['meta'])\n",
    "        trajs.append(traj)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd84d18-72bc-4a87-906d-1d0390a5692c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "task_name = 'visual_manipulation'\n",
    "#task_kwargs=PARTITION_TO_SPECS[\"train\"][task_name]\n",
    "task_kwargs = { 'num_dragged_obj': 1,\n",
    "     'num_base_obj': 1,\n",
    "     'num_other_obj': 0,\n",
    "     'dragged_obj_loc': [2],\n",
    "     'base_obj_loc': [1,3,4],\n",
    "     'third_obj_loc' : [4],\n",
    "     'fourth_obj_loc' : [3],\n",
    "     'possible_dragged_obj': ['flower'],\n",
    "     'possible_dragged_obj_texture': ['red','blue'],\n",
    "     'possible_base_obj': ['bowl'],\n",
    "     'possible_base_obj_texture': ['wooden'],\n",
    "     'possible_third_obj': ['pan'],\n",
    "     'possible_third_obj_texture': ['dark green'],\n",
    "     'possible_fourth_obj': ['pentagon'],\n",
    "     'possible_fourth_obj_texture': ['blue']}\n",
    "#record_gui=True, display_debug_window=True, hide_arm_rgb=False\n",
    "env = vima_bench.make(task_name=task_name,task_kwargs=task_kwargs,hide_arm_rgb=False)\n",
    "\n",
    "num_trajs = 10\n",
    "trajs = gen_trajs(env=env, num_trajs=num_trajs, task_name=task_name, task_kwargs=task_kwargs)\n",
    "pickle.dump(trajs, open('trajs.pkl', 'wb'))\n",
    "env.close()\n",
    "#obs = env.reset()\n",
    "#top_obs = obs['rgb']['top']\n",
    "#top_obs = np.rollaxis(top_obs,0,3)\n",
    "#plt.imshow(top_obs)\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37af6ed-6453-4039-9991-1867326f76a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNPolicy(\n",
       "  (cnn_state): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Flatten()\n",
       "    (10): Linear(in_features=160, out_features=100, bias=True)\n",
       "  )\n",
       "  (mask): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Flatten()\n",
       "    (10): Linear(in_features=160, out_features=100, bias=True)\n",
       "  )\n",
       "  (policy): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=100, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tasks = len(trajs)\n",
    "\n",
    "act_size = trajs[0]['acts'][0].shape[0]\n",
    "hidden_size = 100\n",
    "\n",
    "policy = CNNPolicy(act_size, hidden_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f944079-cc65-4016-8964-28c447c748f8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "batch_size = 10\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(policy.parameters()))\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(trajs)))\n",
    "\n",
    "num_batches = len(idxs) // batch_size\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    np.random.shuffle(idxs)\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_idx = np.random.randint(len(trajs), size=(batch_size,)) # Indices of traj\n",
    "        t_idx_pertraj = np.random.randint(1, size=(batch_size,)) # Indices of timesteps in traj\n",
    "        t_states = np.concatenate([trajs[c_idx]['obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_target_states = np.concatenate([trajs[c_idx]['target_obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_actions = np.concatenate([trajs[c_idx]['acts'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "   \n",
    "        t_states = torch.Tensor(t_states).float().to(device)\n",
    "        t_target_states = torch.Tensor(t_target_states).float().to(device)\n",
    "        t_actions = torch.Tensor(t_actions).float().to(device)\n",
    "        \n",
    "        a_preds = policy(t_states, t_target_states)[0]\n",
    "        loss = torch.mean(torch.linalg.norm(a_preds - t_actions, dim=-1)) # supervised learning loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "torch.save(policy, 'policy_mask.pt')\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65273f-67ff-4e56-9572-7bed80c70d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_name = \"sweep_without_touching\"\n",
    "#task_kwargs = {}\n",
    "#task_kwargs = { 'num_dragged_obj': 1,\n",
    "#     'num_base_obj': 1,\n",
    "#     'num_other_obj': 0,\n",
    "#     'dragged_obj_loc': [2],\n",
    "#     'base_obj_loc': [3],\n",
    "#     'third_obj_loc' : [4],\n",
    "#     'fourth_obj_loc' : [3],\n",
    "#     'possible_dragged_obj': ['flower'],\n",
    "#     'possible_dragged_obj_texture': ['yellow'],\n",
    "#     'possible_base_obj': ['bowl'],\n",
    "#     'possible_base_obj_texture': ['wooden'],\n",
    "#     'possible_third_obj': ['pan'],\n",
    "#     'possible_third_obj_texture': ['tiger'],\n",
    "#     'possible_fourth_obj': ['pentagon'],\n",
    "#     'possible_fourth_obj_texture': ['blue']}\n",
    "record_cfg = {'save_video': True,\n",
    "     'save_video_path': './rollouts/',\n",
    "     'view': 'front',\n",
    "     'fps': 20,\n",
    "     'video_height': 640,\n",
    "     'video_width': 720}\n",
    "# record_gui=True, display_debug_window=True, hide_arm_rgb=False\n",
    "env = vima_bench.make(task_name=task_name,task_kwargs=None,hide_arm_rgb=False,record_cfg=record_cfg)\n",
    "#obs = env.reset()\n",
    "#segm = obs['segm']['top']\n",
    "#top_obs = obs['rgb']['top']\n",
    "#top_obs = np.rollaxis(top_obs,0,3)\n",
    "#plt.imshow(remove_obj(segm, top_obs, 'dragged'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ea11f-deb6-46cd-8a73-a48cc14f5aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oracle = True\n",
    "\n",
    "if oracle:\n",
    "    task = env.task\n",
    "    oracle_fn = task.oracle(env)\n",
    "else:\n",
    "    policy = torch.load('policy_mask.pt')\n",
    "    policy.eval()\n",
    "\n",
    "obj_to_remove = None#['base']\n",
    "num_test_trajs = 1\n",
    "video = True\n",
    "\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.ylim(0.3, 0.7)\n",
    "\n",
    "successes = []\n",
    "\n",
    "rollouts = {'actions': [], 'action_starts': [],'action_ends': [], 'true_starts': [], 'true_ends': []}\n",
    "\n",
    "for i in tqdm(range(num_test_trajs)):\n",
    "    os.makedirs('rollouts/' + str(i), exist_ok=True)\n",
    "    obs = env.reset()\n",
    "    \n",
    "    if video:\n",
    "        video_name = str(i)\n",
    "        env.start_rec(video_name)\n",
    "    for step in range(3):\n",
    "        if oracle:\n",
    "            oracle_action = oracle_fn.act(obs)\n",
    "            # clip action\n",
    "            oracle_action = {\n",
    "                k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "                for k, v in oracle_action.items()\n",
    "            }\n",
    "            obs, _, done, info = env.step(action=oracle_action, skip_oracle=False)\n",
    "        \n",
    "        else:\n",
    "            segm = obs['segm']['top']\n",
    "            target_obs = find_target(segm)\n",
    "            top_obs = obs['rgb']['top']\n",
    "            top_obs = np.rollaxis(top_obs,0,3)\n",
    "\n",
    "            if obj_to_remove is not None:\n",
    "                obj_removed = random.choice(obj_to_remove)\n",
    "                segm = obs['segm']['top']\n",
    "                top_obs = remove_obj(segm, top_obs, obj_removed)\n",
    "            first_obs = top_obs.copy()\n",
    "\n",
    "            im = Image.fromarray(top_obs)\n",
    "            im.save('rollouts/'+str(i)+\"/\"+str(step)+'.jpg')\n",
    "            top_obs = downsize_obs(top_obs)\n",
    "            segm_obs = downsize_segm(target_obs)\n",
    "            state = torch.Tensor(top_obs[None]).to(device)\n",
    "            target_state = torch.Tensor(segm_obs[None]).to(device)\n",
    "            action = policy(state, target_state).cpu().detach().numpy()[0]\n",
    "            \n",
    "            rollouts['actions'].append(action)\n",
    "            rollouts['action_starts'].append(action[0:2].copy())\n",
    "            rollouts['action_ends'].append(action[6:8].copy())\n",
    "            obs, _, done, info = env.step(action=reconstruct_act(action), skip_oracle=False)\n",
    "        \n",
    "        if done:\n",
    "            successes.append(1)\n",
    "        else:\n",
    "            successes.append(0)\n",
    "            \n",
    "    if video:\n",
    "        env.end_rec()\n",
    "        \n",
    "    top_obs = obs['rgb']['top']\n",
    "    top_obs = np.rollaxis(top_obs,0,3)\n",
    "    \n",
    "    if obj_to_remove is not None:\n",
    "        segm = obs['segm']['top']\n",
    "        top_obs = remove_obj(segm, top_obs, obj_removed)\n",
    "        \n",
    "    im = Image.fromarray(top_obs)\n",
    "    im.save('rollouts/'+str(i)+\"/\"+str(step+1)+'.jpg')\n",
    "\n",
    "env.close()\n",
    "\n",
    "#if not oracle:\n",
    "#    plt.scatter(np.array(rollouts['true_starts'])[:, 1], np.array(rollouts['true_starts'])[:, 0], marker='o', color='g', label='gt starts')\n",
    "#    plt.scatter(np.array(rollouts['true_ends'])[:, 1], np.array(rollouts['true_ends'])[:, 0], marker='x', color='g', label='gt ends')\n",
    "#    plt.scatter(np.array(rollouts['action_starts'])[:, 1], np.array(rollouts['action_starts'])[:, 0], marker='o', color='r', label='rollout starts')\n",
    "#    plt.scatter(np.array(rollouts['action_ends'])[:, 1], np.array(rollouts['action_ends'])[:, 0], marker='x', color='r', label='rollout ends')\n",
    "#    plt.gca().invert_yaxis()\n",
    "#    plt.legend()\n",
    "print(sum(successes)/len(successes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38521b41-8dff-4dd9-aca2-61fe44243985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
