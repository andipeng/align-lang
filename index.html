<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">

<!-- jQuery library -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.4/dist/jquery.slim.min.js"></script>

<!-- Popper JS -->
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>

<!-- Latest compiled JavaScript -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 
<link href="https://fonts.googleapis.com/css2?family=Lato&display=swap"
      rel="stylesheet">
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">

<body>
<div class="container">
    <div class="title">
        Language-Guided State Abstractions
    </div>

    <div class="venue">
        ICLR 2024, HRI 2024
    </div>

    <br><br>

    <div class="author">
        <a href="https://andipeng.com/">Andi Peng</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://belindal.github.io/">Belinda Z. Li</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://ilia10000.github.io/">Ilia Sucholutsky</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://www.tedsumers.info/">Theodore R. Sumers</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://nishanthjkumar.com/">Nishanth Kumar</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://andreea7b.github.io/">Andreea Bobu</a><sup>3</sup>
    </div>
    <div class="author">
        <a href="https://cocosci.princeton.edu/tom/index.php">Thomas L. Griffiths</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://www.mit.edu/~jda/">Jacob Andreas</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://interactive.mit.edu/about/people/julie">Julie A. Shah</a><sup>1</sup>
    </div>

    <br><br>

    <div class="affiliation"><sup>1&nbsp;</sup>MIT</div>
    <div class="affiliation"><sup>2&nbsp;</sup>Princeton</div>
    <div class="affiliation"><sup>3&nbsp;</sup>The AI Institute</div>
    

    <br><br>
    <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://arxiv.org/pdf/2402.18759.pdf">
                <span class="material-icons"> </span> 
                 ICLR Paper
            </a>
            <a class="paper-btn" href="https://arxiv.org/pdf/2402.03081.pdf">
                <span class="material-icons"> </span> 
                 HRI Paper
            </a>
            </div>
    </div>

    <br><br>

    <h1></h1>
    <div class="video-container">
        <iframe src="./resources/video.mp4" frameBorder="0"
                allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
    </div>

    <br><br>

    <h1>Summary</h1>
    <p style="width: 80%; text-align: left">
        <br> Generalizable policy learning in high-dimensional observation spaces is facilitated by well-designed state representations, which can surface important features of an environment and hide irrelevant ones. These state representations are typically manually specified, or derived from other labor-intensive labeling procedures. We introduce two methods, LGA (language-guided abstraction) and PLGA (preference-conditioned language-guided abstraction), which use a combination of natural language supervision and background knowledge from language models (LMs) to automatically build state representations tailored to unseen tasks. In LGA, a user first provides a (possibly incomplete) description of a target task in natural language; next, a pre-trained LM translates this task description into a state abstraction function that masks out irrelevant features; finally, an imitation policy is trained using a small number of demonstrations and LGAgenerated abstract states. In PLGA, we observe that these abstractions also depend on a userâ€™s preference for what matters in a task, which may be hard to describe or infeasible to exhaustively specify using language alone. Ergo, we propose using language models (LMs) to query for those preferences directly given knowledge that a change in behavior has occurred. In PLGA, we use the LM in two ways: first, given a text description of the task and knowledge of behavioral change between states, we query the LM for possible hidden preferences; second, given the most likely preference, we query the LM to construct the state abstraction.
    <br>
    <hr>

    <h1>LGA</h1>
    <img style="width: 90%;" src="./resources/lga.png" alt="Teaser figure."/>
    <p style="width: 80%; text-align: left"><b>(A)</b>: Example demonstration in our environment, showing Spot picking up an orange and bringing it to the user. <b>(B)</b>: Our approach, Language Guided Abstraction (LGA), uses natural language supervision to create a state abstraction with task-relevant features identified by an LM. The policy is learned directly over this abstracted state.</p>
    <h1>PLGA</h1>
    <img style="width: 90%;" src="./resources/plga.png" alt="Teaser figure."/>
    <p style="width: 80%; text-align: left"><b>(Left)</b>: The robot uses a contrastive demonstration pair to identify a behavior change not captured by the language specification. Given this information, we query the LM for potential preferences that could explain this change. Finally, the robot uses its best preference estimate to query the LM for state abstractions and train a policy. <b>(Right)</b>: At test time, the robot generalizes to new states and language specifications using its preference-conditioned abstractions.</p>
    <br><br>

    <br>
    <hr>

    <div class="columns is-centered">
        <div class="column">
          <h2 class="title is-3"><b>LGA</b> learns policies robust policies to object poses, visual distractors and physical disturbances</h2>
          <section class="hero is-light is-small">
            <div class="hero-body">
                <div class="container">
                  <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-steve">
                      <video poster="" id="steve" autoplay controls muted loop  height=300px>
                        <source src="materials/videos/booknshelfrealtime.mp4"
                                type="video/mp4">
                      </video>
                    </div>
                    <div class="item item-chair-tp">
                      <video poster="" id="chair-tp" autoplay controls muted loop  height=300px>
                        <source src="materials/videos/mugrealtime2.mp4"
                                type="video/mp4">
                      </video>
                    </div>
                    <div class="item item-shiba">
                      <video poster="" id="shiba" autoplay controls muted loop  height=300px>
                        <source src="materials/videos/cabinetrealtime2.mp4"
                                type="video/mp4">
                      </video>
                    </div>
                    <div class="item item-fullbody">
                      <video poster="" id="fullbody" autoplay controls muted loop  height=300px>
                        <source src="materials/videos/dishinrackdisturbances.mp4"
                                type="video/mp4">
                      </video>
                    </div>
                    <div class="item item-blueshirt">
                      <video poster="" id="blueshirt" autoplay controls muted loop  height=300px>
                        <source src="materials/videos/drawerrealtime2.mp4"
                                type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>
              </div>
          </section>
        </div>
    </div>

    <br>
    <hr>
    <h1>Paper</h1>
    <div class="paper-thumbnail">
        <a href="https://arxiv.org/pdf/2307.06333.pdf">
            <img class="layered-paper-big" width="100%" src="./resources/paper.svg" alt="Paper thumbnail"/>
        </a>
    </div>
    <div class="paper-info">
        <h3>Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation</h3>
        <p>Andi Peng, Aviv Netanyahu, Mark Ho, Tianmin Shu, Andreea Bobu, Julie Shah, and Pulkit Agrawal</p>
        <pre><code>@inproceedings{peng2023diagnosis,
    title = {Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation},
    author = {Peng, Andi and Netanyahu, Aviv and Ho, Mark and Shu, Tianmin and Bobu, Andreea and Shah, Julie and Agrawal, Pulkit},
    year = {2023},
    booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML) 2023}
}</code></pre>
    </div>

    <br>
    <br>
    <hr>

 <section id="paper">
        <h2>Team</h2>        
        <div class="row">
            <div class="column5">
                <a href='https://andipeng.com/'>
                    <img src=./resources/people/andi.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Andi Peng </p>
                <p class=institution>MIT</p>
            </div>

            <div class="column5">
                <a href='https://belindal.github.io/'>
                    <img  src=./resources/people/belinda.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Belinda Z. Li </p>
                <p class=institution>MIT</p>
            </div>

            <div class="column5">
                <a href='https://ilia10000.github.io/'>
                    <img  src=./resources/people/ilia.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Ilia Sucholutsky </p>
                <p class=institution>Princeton</p>
            </div>

            <div class="column5">
                <a href='https://www.tedsumers.info/'>
                    <img  src=./resources/people/ted.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Theodore R. Sumers </p>
                <p class=institution>Princeton</p>
            </div>

            <div class="column5">
                <a href='https://nishanthjkumar.com/'>
                    <img  src=./resources/people/nishanth.jpeg class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Nishanth Kumar </p>
                <p class=institution>MIT</p>
            </div>

            <div class="column5">
                <a href='https://andreea7b.github.io/'>
                    <img  src=./resources/people/andreea.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Andreea Bobu </p>
                <p class=institution>The AI Institute</p>
            </div>

            <div class="column5">
                <a href='https://cocosci.princeton.edu/tom/index.php'>
                    <img  src=./resources/people/tom.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Thomas L. Griffiths </p>
                <p class=institution>Princeton</p>
            </div>

            <div class="column5">
                <a href='https://www.mit.edu/~jda/'>
                    <img  src=./resources/people/jacob.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Jacob Andreas </p>
                <p class=institution>MIT</p>
            </div>

            <div class="column5">
                <a href='https://interactive.mit.edu/about/people/julie'>
                    <img  src=./resources/people/julie.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Julie A. Shah </p>
                <p class=institution>MIT</p>
            </div>
    </section>

    <hr>
    <h1>Acknowledgements</h1>
    <p style="width: 80%;">
        This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
        and <a href="http://richzhang.github.io/">Richard Zhang</a> for a
        <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project, and
        adapted to be mobile responsive by <a href="https://github.com/jasonyzhang/webpage-template">Jason Zhang</a>.
        The code we built on can be found <a href="https://github.com/elliottwu/webpage-template">here</a>.
    </p>

    <br>
</div>

</body>

</html>
