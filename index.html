<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">

<!-- jQuery library -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.4/dist/jquery.slim.min.js"></script>

<!-- Popper JS -->
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>

<!-- Latest compiled JavaScript -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 
<link href="https://fonts.googleapis.com/css2?family=Lato&display=swap"
      rel="stylesheet">
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">

<body>
<div class="container">
    <div class="title">
        Language-Guided State Abstractions
    </div>

    <div class="venue">
        ICLR 2024, HRI 2024
    </div>

    <br><br>

    <div class="author">
        <a href="https://andipeng.com/">Andi Peng</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://belindal.github.io/">Belinda Z. Li</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://ilia10000.github.io/">Ilia Sucholutsky</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://www.tedsumers.info/">Theodore R. Sumers</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://nishanthjkumar.com/">Nishanth Kumar</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://andreea7b.github.io/">Andreea Bobu</a><sup>3</sup>
    </div>
    <div class="author">
        <a href="https://cocosci.princeton.edu/tom/index.php">Thomas L. Griffiths</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://www.mit.edu/~jda/">Jacob Andreas</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://interactive.mit.edu/about/people/julie">Julie A. Shah</a><sup>1</sup>
    </div>

    <br><br>

    <div class="affiliation"><sup>1&nbsp;</sup>MIT</div>
    <div class="affiliation"><sup>2&nbsp;</sup>Princeton</div>
    <div class="affiliation"><sup>3&nbsp;</sup>The AI Institute</div>
    

    <br><br>

    <div class="links"><a href="https://arxiv.org/pdf/2402.18759.pdf"><i class="fa fa-file-text", style="font-size: 50px; padding-bottom: 10px"></i><br>[ICLR Paper]</a></div>
    <div class="links"><a href="https://arxiv.org/pdf/2402.03081.pdf"><i class="fa fa-file-text", style="font-size: 50px; padding-bottom: 10px"></i><br>[HRI Paper]</a></div>

    <br><br>

    <h1></h1>
    <div class="video-container">
        <iframe src="./resources/video.mp4" frameBorder="0"
                allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
    </div>

    <br><br>

    <h1>Summary</h1>
    <p style="width: 80%; text-align: left">
        <br> Generalizable policy learning in high-dimensional observation spaces is facilitated by well-designed state representations, which can surface important features of an environment and hide irrelevant ones. These state representations are typically manually specified, or derived from other labor-intensive labeling procedures. We introduce two methods, LGA (language-guided abstraction) and PLGA (preference-conditioned language-guided abstraction), which use a combination of natural language supervision and background knowledge from language models (LMs) to automatically build state representations tailored to unseen tasks. In LGA, a user first provides a (possibly incomplete) description of a target task in natural language; next, a pre-trained LM translates this task description into a state abstraction function that masks out irrelevant features; finally, an imitation policy is trained using a small number of demonstrations and LGAgenerated abstract states. In PLGA, we observe that these abstractions also depend on a userâ€™s preference for what matters in a task, which may be hard to describe or infeasible to exhaustively specify using language alone. Ergo, we propose using language models (LMs) to query for those preferences directly given knowledge that a change in behavior has occurred. In PLGA, we use the LM in two ways: first, given a text description of the task and knowledge of behavioral change between states, we query the LM for possible hidden preferences; second, given the most likely preference, we query the LM to construct the state abstraction.
    <br>
    <hr>

    <h1>LGA</h1>
    <img style="width: 90%;" src="./resources/lga.png" alt="Teaser figure."/>
    <h1>PLGA</h1>
    <img style="width: 90%;" src="./resources/plga.png" alt="Teaser figure."/>
    <br><br>

    <br>
    <hr>

    <h1>Framework Overview</h1>

    <br>
    <h2>Diagnosing Distribution Shift Failures</h2>
    <p style="width: 80%; text-align: left">Policies can fail due to different distribution shifts. The figure below shows illustrative distribution shifts for task: <b>``Get my mug."</b> Shifted concepts can be state-based (a changed object) and also reward-based (dependent on user preference). We can deploy data augmentation for <i>task-irrelevant</i> shifts (green checks), a subset where the modified state <i>does not impact</i> desired policy behaviour. But how do we know what's task-irrelevant vs. -relevant for each user?</p>
    <img style="width: 70%;" src="./resources/shifts.png" alt="shifts."/>

    <br>
    <br>
    <h2>Generating Counterfactual Demonstrations for Human Feedback</h2>
    <p style="width: 80%; text-align: left">Our key insight is that <i>end users are uniquely positioned to recognize which concepts are relevant or irrelevant for their desired task.</i> But how do we elicit good concept-level human feedback? We propose a counterfactual approach to identify failure. Consider that the human also observes a trajectory of the robot successfully retrieving the object in the same scenario but with a single change -- the pan being blue instead of striped. Being able to contrast the two trajectories of successful and unsuccessful behaviour can better position the user to identify visual concepts impacting failure. Here, the user may identify pan material to be a task-irrelevant concept, which can then be used to make the policy invariant to this concept via data augmentation.</p>
    <img style="width: 45%; text-align: left" src="./resources/counterfactual.png" alt="counterfactual."/>
    <img style="width: 40%;" src="./resources/algo.png" alt="algo."/>
    
    <br>
    <br>
    <h2>Adaptation to Personalized User Objectives</h2>
    <p style="width: 80%; text-align: left">We test our framework in three domains consisting of both discrete and continuous control tasks with real human users. Through human experiments, we verify our main hypothesis that user feedback resulting from counterfactual demonstrations significantly improves the accuracy of user-identified TI concepts as well as the data efficiency of policy finetuning with <i>less user effort</i>. </p>
    <img style="width: 70%;" src="./resources/accuracy.png" alt="accuracy."/>

    <br>
    <br>
     <p style="width: 80%; text-align: left">Moreover, policies finetuned using this human feedback (CF-H) result in higher performance with less expert demonstrations required compared to baselines. These findings illustrate a promising direction into leveraging end users to more efficiently perform interactive alignment of robotic policies at test-time. </p>
     <img style="width: 70%;" src="./resources/finetuning.png" alt="finetuning."/>
     <br>

    <br>
    <hr>
    <h1>Paper</h1>
    <div class="paper-thumbnail">
        <a href="https://arxiv.org/pdf/2307.06333.pdf">
            <img class="layered-paper-big" width="100%" src="./resources/paper.svg" alt="Paper thumbnail"/>
        </a>
    </div>
    <div class="paper-info">
        <h3>Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation</h3>
        <p>Andi Peng, Aviv Netanyahu, Mark Ho, Tianmin Shu, Andreea Bobu, Julie Shah, and Pulkit Agrawal</p>
        <pre><code>@inproceedings{peng2023diagnosis,
    title = {Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation},
    author = {Peng, Andi and Netanyahu, Aviv and Ho, Mark and Shu, Tianmin and Bobu, Andreea and Shah, Julie and Agrawal, Pulkit},
    year = {2023},
    booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML) 2023}
}</code></pre>
    </div>

    <br>
    <br>
    <hr>

 <section id="paper">
        <h2>Team</h2>        
        <div class="row">
            <div class="column5">
                <a href='https://andipeng.com/'>
                    <img src=./resources/people/andi.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Andi Peng </p>
                <p class=institution>MIT</p>
            </div>

            <div class="column5">
                <a href='https://belindal.github.io/'>
                    <img  src=./resources/people/belinda.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Belinda Z. Li </p>
                <p class=institution>MIT</p>
            </div>

            <div class="column5">
                <a href='https://ilia10000.github.io/'>
                    <img  src=./resources/people/ilia.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Ilia Sucholutsky </p>
                <p class=institution>Princeton</p>
            </div>

            <div class="column5">
                <a href='https://www.tedsumers.info/'>
                    <img  src=./resources/people/ted.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Theodore R. Sumers </p>
                <p class=institution>Princeton</p>
            </div>

            <div class="column5">
                <a href='https://nishanthjkumar.com/'>
                    <img  src=./resources/people/nishanth.jpeg class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Nishanth Kumar </p>
                <p class=institution>MIT</p>
            </div>

            <div class="column5">
                <a href='https://andreea7b.github.io/'>
                    <img  src=./resources/people/andreea.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Andreea Bobu </p>
                <p class=institution>The AI Institute</p>
            </div>

            <div class="column5">
                <a href='https://cocosci.princeton.edu/tom/index.php'>
                    <img  src=./resources/people/tom.jpg class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Thomas L. Griffiths </p>
                <p class=institution>Princeton</p>
            </div>

            <div class="column5">
                <a href='https://www.mit.edu/~jda/'>
                    <img  src=./resources/people/jacob.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Jacob Andreas </p>
                <p class=institution>MIT</p>
            </div>

            <div class="column5">
                <a href='https://interactive.mit.edu/about/people/julie'>
                    <img  src=./resources/people/julie.png class="figure-img img-fluid rounded-circle" height=180px width=180px>
                </a>
                <p class=profname> Julie A. Shah </p>
                <p class=institution>MIT</p>
            </div>
    </section>

    <hr>
    <h1>Acknowledgements</h1>
    <p style="width: 80%;">
        This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
        and <a href="http://richzhang.github.io/">Richard Zhang</a> for a
        <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project, and
        adapted to be mobile responsive by <a href="https://github.com/jasonyzhang/webpage-template">Jason Zhang</a>.
        The code we built on can be found <a href="https://github.com/elliottwu/webpage-template">here</a>.
    </p>

    <br>
</div>

</body>

</html>
