{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77db741a-d9b8-4cd4-acdd-c2477e5e6a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Sep 21 2023 11:56:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 17 tasks loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import io\n",
    "import json\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import distributions as pyd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode - o\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "lang_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "import vima_bench\n",
    "from vima_bench import PARTITION_TO_SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0f9ffc-1863-416a-887e-44f008b71c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "                \n",
    "# helper mlp init function\n",
    "def mlp(input_dim, output_dim, hidden_dim, hidden_depth, output_mod=None):\n",
    "    if hidden_depth == 0:\n",
    "        mods = [nn.Linear(input_dim, output_dim)]\n",
    "    else:\n",
    "        mods = [nn.Linear(input_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        for i in range(hidden_depth - 1):\n",
    "            mods += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        mods.append(nn.Linear(hidden_dim, output_dim))\n",
    "    if output_mod is not None:\n",
    "        mods.append(output_mod)\n",
    "    trunk = nn.Sequential(*mods)\n",
    "    return trunk\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.size(0), -1)\n",
    "\n",
    "# CNN policy\n",
    "class GCBCPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, action_dim, hidden_size, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,72)=>(b_size,32,8,17)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,17)=>(b_size,64,3,7)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(), #(b_size,64,3,7)=>(b_size,32,1,5)=>(b_size,32*1*5)\n",
    "            nn.Linear(32*1*5, hidden_size)#, nn.LeakyReLU(inplace=True), nn.BatchNorm1d(32), #(b_size,32*1*5)=>(b_size,action_dim)\n",
    "        )\n",
    "        self.policy = mlp(hidden_size+384, action_dim, hidden_dim=100, hidden_depth=1)\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, state, goal):\n",
    "        state = state/255.0 # process image + switch channels\n",
    "        state = state.permute(0,3,1,2)\n",
    "        state_embed = self.cnn(state)\n",
    "        \n",
    "        gc_embed = torch.cat([state_embed, goal], dim=1)\n",
    "        action = self.policy(gc_embed)\n",
    "        return action\n",
    "\n",
    "class BCPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, action_dim, hidden_size, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,72)=>(b_size,32,8,17)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,17)=>(b_size,64,3,7)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(), #(b_size,64,3,7)=>(b_size,32,1,5)=>(b_size,32*1*5)\n",
    "            nn.Linear(32*1*5, action_dim)#, nn.LeakyReLU(inplace=True), nn.BatchNorm1d(32), #(b_size,32*1*5)=>(b_size,action_dim)\n",
    "        )\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = state/255.0 # process image + switch channels\n",
    "        state = state.permute(0,3,1,2)\n",
    "        action = self.cnn(state)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07cbd67-71e4-4c60-8662-070077913cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_act(action):\n",
    "    return np.concatenate(list(action.values())).ravel()\n",
    "\n",
    "# reconstructs actions for simulator\n",
    "def reconstruct_act(action):\n",
    "    reconst_action = {}\n",
    "    reconst_action['pose0_position'] = np.array(action[0:2])\n",
    "    reconst_action['pose0_rotation'] = np.array(action[2:6])\n",
    "    reconst_action['pose1_position'] = np.array(action[6:8])\n",
    "    reconst_action['pose1_rotation'] = np.array(action[8:12])\n",
    "    reconst_action = {\n",
    "        k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "        for k, v in reconst_action.items()\n",
    "    }\n",
    "    return reconst_action\n",
    "\n",
    "def process_obs(obs):\n",
    "    obs = np.rollaxis(obs,0,3)\n",
    "    cv2.imwrite('temp.jpg', obs)\n",
    "    img = cv2.imread('temp.jpg')\n",
    "    processed_obs = cv2.resize(img, dsize=(72, 36), interpolation=cv2.INTER_CUBIC)\n",
    "    return processed_obs\n",
    "\n",
    "def process_segm(segm, phi_hat, env_obj_info):\n",
    "    # searches if obj + properties are in phi_hat, replaces with mask\n",
    "    for obj in env_obj_info:\n",
    "        if env_obj_info[obj]['obj_name'] in phi_hat.keys():\n",
    "            if env_obj_info[obj]['texture_name'] in phi_hat[env_obj_info[obj]['obj_name']]:\n",
    "                segm[segm == obj] = 255\n",
    "    segm[segm < 255] = 0\n",
    "    # reshape + resize\n",
    "    segm = cv2.merge((segm,segm,segm))\n",
    "    segm = cv2.resize(segm, dsize=(72, 36), interpolation=cv2.INTER_LINEAR_EXACT)\n",
    "    return segm\n",
    "\n",
    "def remove_obj(segm, obs, remove_obj):\n",
    "    #if remove_obj == 'arm':\n",
    "    #    segm = (segm == 2).astype(int)\n",
    "    if remove_obj == 'base':\n",
    "        segm = (segm == 5).astype(int)\n",
    "    elif remove_obj == 'dragged':\n",
    "        segm = (segm == 6).astype(int)\n",
    "    elif remove_obj == 'distractor':\n",
    "        segm = (segm == 7).astype(int)\n",
    "    segm = np.atleast_3d(segm)\n",
    "    \n",
    "    for height in range(128):\n",
    "        for width in range(256):\n",
    "            if segm[height, width] == 1:\n",
    "                obs[height, width] = 47\n",
    "    return obs\n",
    "\n",
    "def compare_actions(actions, gt_action):\n",
    "    comparisons = []\n",
    "    for action in actions:\n",
    "        comparisons.append(np.linalg.norm(gt_action - action[[0,1,6,7]],ord=2))\n",
    "    return comparisons\n",
    "\n",
    "# generates random trajs within specified constraints\n",
    "def gen_trajs(env, num_trajs, task_name, task_kwargs, goal, phi_hat):\n",
    "    trajs = []\n",
    "    task = env.task\n",
    "    oracle_fn = task.oracle(env)\n",
    "    for traj in tqdm(range(num_trajs)):\n",
    "        traj = {'obs': [], 'mask_obs': [], 'acts': [], 'goals':[], 'meta': []}\n",
    "        obs = env.reset()\n",
    "        traj['meta'] = env.meta_info\n",
    "        obj_type = env.meta_info['obj_id_to_info'][6]['obj_name']\n",
    "        goal_embed = lang_model.encode(obj_type)\n",
    "        for step in range(1):\n",
    "            mask_obs = obs['segm']['top'] # extracts segm\n",
    "            top_obs = obs['rgb']['top'] # extracts top down view only\n",
    "            traj['obs'].append(process_obs(top_obs))\n",
    "            traj['mask_obs'].append(process_segm(mask_obs, phi_hat, env.meta_info['obj_id_to_info']))\n",
    "            traj['goals'].append(goal_embed)\n",
    "            # prompt, prompt_assets = env.prompt, env.prompt_assets\n",
    "            oracle_action = oracle_fn.act(obs)\n",
    "            # clip action\n",
    "            oracle_action = {\n",
    "                k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "                for k, v in oracle_action.items()\n",
    "            }\n",
    "            traj['acts'].append(flatten_act(oracle_action))\n",
    "            obs, _, done, info = env.step(action=oracle_action, skip_oracle=False)\n",
    "        traj['obs'] = np.array(traj['obs'])\n",
    "        traj['mask_obs'] = np.array(traj['mask_obs'])\n",
    "        traj['acts'] = np.array(traj['acts'])\n",
    "        traj['goals'] = np.array(traj['goals'])\n",
    "        traj['meta'] = np.array(traj['meta'])\n",
    "        trajs.append(traj)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fccfc2f6-2659-4640-b9d6-0a7546455ef9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "lang_goal = 'bring me the bowl'\n",
    "lang_embed = lang_model.encode(lang_goal)\n",
    "phi_hat = {\n",
    "    'block': ['red'],\n",
    "}\n",
    "\n",
    "task_name = 'visual_manipulation'\n",
    "#task_kwargs = {'num_dragged_obj': 1,\n",
    "#               'num_distractors_obj': 0,\n",
    "#               'possible_angles_of_rotation': 120,\n",
    "#               'possible_dragged_obj': ['pan'],\n",
    "#               'possible_dragged_obj_texture': ['blue']}\n",
    "task_kwargs = { \n",
    "    'num_dragged_obj': 1,\n",
    "    'num_base_obj': 1,\n",
    "    'num_other_obj': 1,\n",
    "    'dragged_obj_loc': [1],\n",
    "    'base_obj_loc': [4],\n",
    "    'third_obj_loc' : [3],\n",
    "    'fourth_obj_loc' : [2],\n",
    "    'possible_dragged_obj': ['tomato'],\n",
    "    'possible_dragged_obj_texture': ['green'],\n",
    "    'possible_base_obj': ['square'],\n",
    "    'possible_base_obj_texture': ['blue'],\n",
    "    'possible_third_obj': ['tomato'],\n",
    "    'possible_third_obj_texture': ['red'],\n",
    "    'possible_fourth_obj': ['tomato'],\n",
    "    'possible_fourth_obj_texture': ['green']\n",
    "}\n",
    "#record_gui=True, display_debug_window=True, hide_arm_rgb=False\n",
    "env = vima_bench.make(task_name=task_name,task_kwargs=task_kwargs,hide_arm_rgb=False)\n",
    "\n",
    "num_trajs = 5\n",
    "trajs = gen_trajs(env=env, num_trajs=num_trajs, task_name=task_name, task_kwargs=task_kwargs, goal=lang_embed, phi_hat=phi_hat)\n",
    "pickle.dump(trajs, open('trajs.pkl', 'wb'))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082b88c2-3372-4b12-b64e-3b7d4cf43f4d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCPolicy(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Flatten()\n",
       "    (10): Linear(in_features=160, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tasks = len(trajs)\n",
    "\n",
    "act_size = trajs[0]['acts'][0].shape[0]\n",
    "hidden_size = 100\n",
    "\n",
    "#policy = GCBCPolicy(act_size, hidden_size)\n",
    "policy = BCPolicy(act_size, hidden_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dde3ee5-ce6a-41eb-ac85-860781776e8f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 1.61062396\n",
      "[2,     1] loss: 1.61367834\n",
      "[3,     1] loss: 1.59098458\n",
      "[4,     1] loss: 1.57353747\n",
      "[5,     1] loss: 1.58623242\n",
      "[6,     1] loss: 1.57087910\n",
      "[7,     1] loss: 1.56873393\n",
      "[8,     1] loss: 1.53686786\n",
      "[9,     1] loss: 1.54649568\n",
      "[10,     1] loss: 1.52772713\n",
      "[11,     1] loss: 1.51567709\n",
      "[12,     1] loss: 1.49084020\n",
      "[13,     1] loss: 1.49254262\n",
      "[14,     1] loss: 1.48371851\n",
      "[15,     1] loss: 1.45930648\n",
      "[16,     1] loss: 1.43876958\n",
      "[17,     1] loss: 1.43767571\n",
      "[18,     1] loss: 1.41496778\n",
      "[19,     1] loss: 1.39762664\n",
      "[20,     1] loss: 1.37828636\n",
      "[21,     1] loss: 1.36582005\n",
      "[22,     1] loss: 1.35114646\n",
      "[23,     1] loss: 1.31358314\n",
      "[24,     1] loss: 1.27988565\n",
      "[25,     1] loss: 1.27069664\n",
      "[26,     1] loss: 1.24625564\n",
      "[27,     1] loss: 1.21412241\n",
      "[28,     1] loss: 1.19604373\n",
      "[29,     1] loss: 1.16423512\n",
      "[30,     1] loss: 1.13926744\n",
      "[31,     1] loss: 1.10864818\n",
      "[32,     1] loss: 1.08577025\n",
      "[33,     1] loss: 1.05032098\n",
      "[34,     1] loss: 1.03050351\n",
      "[35,     1] loss: 0.99759829\n",
      "[36,     1] loss: 0.95733738\n",
      "[37,     1] loss: 0.92648679\n",
      "[38,     1] loss: 0.89807290\n",
      "[39,     1] loss: 0.86214435\n",
      "[40,     1] loss: 0.82946479\n",
      "[41,     1] loss: 0.78827202\n",
      "[42,     1] loss: 0.75614625\n",
      "[43,     1] loss: 0.72244233\n",
      "[44,     1] loss: 0.68298566\n",
      "[45,     1] loss: 0.64729446\n",
      "[46,     1] loss: 0.60772949\n",
      "[47,     1] loss: 0.56936967\n",
      "[48,     1] loss: 0.53176129\n",
      "[49,     1] loss: 0.49218822\n",
      "[50,     1] loss: 0.45092329\n",
      "[51,     1] loss: 0.41555032\n",
      "[52,     1] loss: 0.36701682\n",
      "[53,     1] loss: 0.34346920\n",
      "[54,     1] loss: 0.29560035\n",
      "[55,     1] loss: 0.26913586\n",
      "[56,     1] loss: 0.21869242\n",
      "[57,     1] loss: 0.18222643\n",
      "[58,     1] loss: 0.17303249\n",
      "[59,     1] loss: 0.15831988\n",
      "[60,     1] loss: 0.11550306\n",
      "[61,     1] loss: 0.12172534\n",
      "[62,     1] loss: 0.11932483\n",
      "[63,     1] loss: 0.12327691\n",
      "[64,     1] loss: 0.11676700\n",
      "[65,     1] loss: 0.10872004\n",
      "[66,     1] loss: 0.11085524\n",
      "[67,     1] loss: 0.11136992\n",
      "[68,     1] loss: 0.10900680\n",
      "[69,     1] loss: 0.10055760\n",
      "[70,     1] loss: 0.08785202\n",
      "[71,     1] loss: 0.07495289\n",
      "[72,     1] loss: 0.08246614\n",
      "[73,     1] loss: 0.07374343\n",
      "[74,     1] loss: 0.07218288\n",
      "[75,     1] loss: 0.08730173\n",
      "[76,     1] loss: 0.08650954\n",
      "[77,     1] loss: 0.05929479\n",
      "[78,     1] loss: 0.07932281\n",
      "[79,     1] loss: 0.06862854\n",
      "[80,     1] loss: 0.05093246\n",
      "[81,     1] loss: 0.05664476\n",
      "[82,     1] loss: 0.06014007\n",
      "[83,     1] loss: 0.04068758\n",
      "[84,     1] loss: 0.04914427\n",
      "[85,     1] loss: 0.04191914\n",
      "[86,     1] loss: 0.05127575\n",
      "[87,     1] loss: 0.04595675\n",
      "[88,     1] loss: 0.04182697\n",
      "[89,     1] loss: 0.04254784\n",
      "[90,     1] loss: 0.04487843\n",
      "[91,     1] loss: 0.02443969\n",
      "[92,     1] loss: 0.04332915\n",
      "[93,     1] loss: 0.04250753\n",
      "[94,     1] loss: 0.02134218\n",
      "[95,     1] loss: 0.03377240\n",
      "[96,     1] loss: 0.04983311\n",
      "[97,     1] loss: 0.04068641\n",
      "[98,     1] loss: 0.05626925\n",
      "[99,     1] loss: 0.05361742\n",
      "[100,     1] loss: 0.04252072\n",
      "[101,     1] loss: 0.03389376\n",
      "[102,     1] loss: 0.04846801\n",
      "[103,     1] loss: 0.03553910\n",
      "[104,     1] loss: 0.05603702\n",
      "[105,     1] loss: 0.06121219\n",
      "[106,     1] loss: 0.05218909\n",
      "[107,     1] loss: 0.04519670\n",
      "[108,     1] loss: 0.06101773\n",
      "[109,     1] loss: 0.05253508\n",
      "[110,     1] loss: 0.05489861\n",
      "[111,     1] loss: 0.03932642\n",
      "[112,     1] loss: 0.05787908\n",
      "[113,     1] loss: 0.04690198\n",
      "[114,     1] loss: 0.04736479\n",
      "[115,     1] loss: 0.03794830\n",
      "[116,     1] loss: 0.04690040\n",
      "[117,     1] loss: 0.02484553\n",
      "[118,     1] loss: 0.03604916\n",
      "[119,     1] loss: 0.04055191\n",
      "[120,     1] loss: 0.03534981\n",
      "[121,     1] loss: 0.05517585\n",
      "[122,     1] loss: 0.04150754\n",
      "[123,     1] loss: 0.04869547\n",
      "[124,     1] loss: 0.03993089\n",
      "[125,     1] loss: 0.03592847\n",
      "[126,     1] loss: 0.02468473\n",
      "[127,     1] loss: 0.04423906\n",
      "[128,     1] loss: 0.02869522\n",
      "[129,     1] loss: 0.05268162\n",
      "[130,     1] loss: 0.04489953\n",
      "[131,     1] loss: 0.04817455\n",
      "[132,     1] loss: 0.04237590\n",
      "[133,     1] loss: 0.03543044\n",
      "[134,     1] loss: 0.02610810\n",
      "[135,     1] loss: 0.03375740\n",
      "[136,     1] loss: 0.06305573\n",
      "[137,     1] loss: 0.04843196\n",
      "[138,     1] loss: 0.04394837\n",
      "[139,     1] loss: 0.04325821\n",
      "[140,     1] loss: 0.06231068\n",
      "[141,     1] loss: 0.03956689\n",
      "[142,     1] loss: 0.03729185\n",
      "[143,     1] loss: 0.03666338\n",
      "[144,     1] loss: 0.03971197\n",
      "[145,     1] loss: 0.04661891\n",
      "[146,     1] loss: 0.01484248\n",
      "[147,     1] loss: 0.03690431\n",
      "[148,     1] loss: 0.02973462\n",
      "[149,     1] loss: 0.04565165\n",
      "[150,     1] loss: 0.04431457\n",
      "[151,     1] loss: 0.04902564\n",
      "[152,     1] loss: 0.06079330\n",
      "[153,     1] loss: 0.03438655\n",
      "[154,     1] loss: 0.03599114\n",
      "[155,     1] loss: 0.05606412\n",
      "[156,     1] loss: 0.04917690\n",
      "[157,     1] loss: 0.05038002\n",
      "[158,     1] loss: 0.03743934\n",
      "[159,     1] loss: 0.02558478\n",
      "[160,     1] loss: 0.02562469\n",
      "[161,     1] loss: 0.04500838\n",
      "[162,     1] loss: 0.05500583\n",
      "[163,     1] loss: 0.03959028\n",
      "[164,     1] loss: 0.01945137\n",
      "[165,     1] loss: 0.04479739\n",
      "[166,     1] loss: 0.02774829\n",
      "[167,     1] loss: 0.05274631\n",
      "[168,     1] loss: 0.06161410\n",
      "[169,     1] loss: 0.05608917\n",
      "[170,     1] loss: 0.04332397\n",
      "[171,     1] loss: 0.02924119\n",
      "[172,     1] loss: 0.04992383\n",
      "[173,     1] loss: 0.03680476\n",
      "[174,     1] loss: 0.04154675\n",
      "[175,     1] loss: 0.02824198\n",
      "[176,     1] loss: 0.03540178\n",
      "[177,     1] loss: 0.04235207\n",
      "[178,     1] loss: 0.03801109\n",
      "[179,     1] loss: 0.02022882\n",
      "[180,     1] loss: 0.04111719\n",
      "[181,     1] loss: 0.07347938\n",
      "[182,     1] loss: 0.05213237\n",
      "[183,     1] loss: 0.03835799\n",
      "[184,     1] loss: 0.04463168\n",
      "[185,     1] loss: 0.04343428\n",
      "[186,     1] loss: 0.02951326\n",
      "[187,     1] loss: 0.03916222\n",
      "[188,     1] loss: 0.02424736\n",
      "[189,     1] loss: 0.03465682\n",
      "[190,     1] loss: 0.04901154\n",
      "[191,     1] loss: 0.05469891\n",
      "[192,     1] loss: 0.05230637\n",
      "[193,     1] loss: 0.03922534\n",
      "[194,     1] loss: 0.05294880\n",
      "[195,     1] loss: 0.04606405\n",
      "[196,     1] loss: 0.04677474\n",
      "[197,     1] loss: 0.03411946\n",
      "[198,     1] loss: 0.05341294\n",
      "[199,     1] loss: 0.04522074\n",
      "[200,     1] loss: 0.04570253\n",
      "[201,     1] loss: 0.02309579\n",
      "[202,     1] loss: 0.05469096\n",
      "[203,     1] loss: 0.05415382\n",
      "[204,     1] loss: 0.06068010\n",
      "[205,     1] loss: 0.05143651\n",
      "[206,     1] loss: 0.04222741\n",
      "[207,     1] loss: 0.05431940\n",
      "[208,     1] loss: 0.03790252\n",
      "[209,     1] loss: 0.04437946\n",
      "[210,     1] loss: 0.03522681\n",
      "[211,     1] loss: 0.03193606\n",
      "[212,     1] loss: 0.02075578\n",
      "[213,     1] loss: 0.04949195\n",
      "[214,     1] loss: 0.04786884\n",
      "[215,     1] loss: 0.02582470\n",
      "[216,     1] loss: 0.04746418\n",
      "[217,     1] loss: 0.07034624\n",
      "[218,     1] loss: 0.02252606\n",
      "[219,     1] loss: 0.03972054\n",
      "[220,     1] loss: 0.04203020\n",
      "[221,     1] loss: 0.04496994\n",
      "[222,     1] loss: 0.04770768\n",
      "[223,     1] loss: 0.05946856\n",
      "[224,     1] loss: 0.05462693\n",
      "[225,     1] loss: 0.03884622\n",
      "[226,     1] loss: 0.03042860\n",
      "[227,     1] loss: 0.06003118\n",
      "[228,     1] loss: 0.05509579\n",
      "[229,     1] loss: 0.04720865\n",
      "[230,     1] loss: 0.03941534\n",
      "[231,     1] loss: 0.04670047\n",
      "[232,     1] loss: 0.04842487\n",
      "[233,     1] loss: 0.05248997\n",
      "[234,     1] loss: 0.05092965\n",
      "[235,     1] loss: 0.04729932\n",
      "[236,     1] loss: 0.03521345\n",
      "[237,     1] loss: 0.03988003\n",
      "[238,     1] loss: 0.02634863\n",
      "[239,     1] loss: 0.01448296\n",
      "[240,     1] loss: 0.03123371\n",
      "[241,     1] loss: 0.03059450\n",
      "[242,     1] loss: 0.02400685\n",
      "[243,     1] loss: 0.03724784\n",
      "[244,     1] loss: 0.04624510\n",
      "[245,     1] loss: 0.04145954\n",
      "[246,     1] loss: 0.07168163\n",
      "[247,     1] loss: 0.05175761\n",
      "[248,     1] loss: 0.05706159\n",
      "[249,     1] loss: 0.05636656\n",
      "[250,     1] loss: 0.03964035\n",
      "[251,     1] loss: 0.04207929\n",
      "[252,     1] loss: 0.06309290\n",
      "[253,     1] loss: 0.05536295\n",
      "[254,     1] loss: 0.03836896\n",
      "[255,     1] loss: 0.04117230\n",
      "[256,     1] loss: 0.04020121\n",
      "[257,     1] loss: 0.04919483\n",
      "[258,     1] loss: 0.04465698\n",
      "[259,     1] loss: 0.03536595\n",
      "[260,     1] loss: 0.04367799\n",
      "[261,     1] loss: 0.04815212\n",
      "[262,     1] loss: 0.04425054\n",
      "[263,     1] loss: 0.03204165\n",
      "[264,     1] loss: 0.05499310\n",
      "[265,     1] loss: 0.07919244\n",
      "[266,     1] loss: 0.06108748\n",
      "[267,     1] loss: 0.04059976\n",
      "[268,     1] loss: 0.03546743\n",
      "[269,     1] loss: 0.04243808\n",
      "[270,     1] loss: 0.02701117\n",
      "[271,     1] loss: 0.04673870\n",
      "[272,     1] loss: 0.04798529\n",
      "[273,     1] loss: 0.03101306\n",
      "[274,     1] loss: 0.06350560\n",
      "[275,     1] loss: 0.06261618\n",
      "[276,     1] loss: 0.03986158\n",
      "[277,     1] loss: 0.05855457\n",
      "[278,     1] loss: 0.03978493\n",
      "[279,     1] loss: 0.04168512\n",
      "[280,     1] loss: 0.02293371\n",
      "[281,     1] loss: 0.02376633\n",
      "[282,     1] loss: 0.04705603\n",
      "[283,     1] loss: 0.05018629\n",
      "[284,     1] loss: 0.06009642\n",
      "[285,     1] loss: 0.05517242\n",
      "[286,     1] loss: 0.03137032\n",
      "[287,     1] loss: 0.06358837\n",
      "[288,     1] loss: 0.05160575\n",
      "[289,     1] loss: 0.02624847\n",
      "[290,     1] loss: 0.05080671\n",
      "[291,     1] loss: 0.04596212\n",
      "[292,     1] loss: 0.03309999\n",
      "[293,     1] loss: 0.05561059\n",
      "[294,     1] loss: 0.03614780\n",
      "[295,     1] loss: 0.03200539\n",
      "[296,     1] loss: 0.04436997\n",
      "[297,     1] loss: 0.01762753\n",
      "[298,     1] loss: 0.04535021\n",
      "[299,     1] loss: 0.06606040\n",
      "[300,     1] loss: 0.03743222\n",
      "[301,     1] loss: 0.03084311\n",
      "[302,     1] loss: 0.02758738\n",
      "[303,     1] loss: 0.04182533\n",
      "[304,     1] loss: 0.07205738\n",
      "[305,     1] loss: 0.03896185\n",
      "[306,     1] loss: 0.04934112\n",
      "[307,     1] loss: 0.05973887\n",
      "[308,     1] loss: 0.04168501\n",
      "[309,     1] loss: 0.02563021\n",
      "[310,     1] loss: 0.04136754\n",
      "[311,     1] loss: 0.03312287\n",
      "[312,     1] loss: 0.04178512\n",
      "[313,     1] loss: 0.06510435\n",
      "[314,     1] loss: 0.04746851\n",
      "[315,     1] loss: 0.05987925\n",
      "[316,     1] loss: 0.04564713\n",
      "[317,     1] loss: 0.04374825\n",
      "[318,     1] loss: 0.05013062\n",
      "[319,     1] loss: 0.04772726\n",
      "[320,     1] loss: 0.03297441\n",
      "[321,     1] loss: 0.05567668\n",
      "[322,     1] loss: 0.04649844\n",
      "[323,     1] loss: 0.03062742\n",
      "[324,     1] loss: 0.05659584\n",
      "[325,     1] loss: 0.06611487\n",
      "[326,     1] loss: 0.05127142\n",
      "[327,     1] loss: 0.03577597\n",
      "[328,     1] loss: 0.01681463\n",
      "[329,     1] loss: 0.03994639\n",
      "[330,     1] loss: 0.05705063\n",
      "[331,     1] loss: 0.02952870\n",
      "[332,     1] loss: 0.02415821\n",
      "[333,     1] loss: 0.02013874\n",
      "[334,     1] loss: 0.02282851\n",
      "[335,     1] loss: 0.03736962\n",
      "[336,     1] loss: 0.03091029\n",
      "[337,     1] loss: 0.06290121\n",
      "[338,     1] loss: 0.02182079\n",
      "[339,     1] loss: 0.03551740\n",
      "[340,     1] loss: 0.03823196\n",
      "[341,     1] loss: 0.02481377\n",
      "[342,     1] loss: 0.05416084\n",
      "[343,     1] loss: 0.03671550\n",
      "[344,     1] loss: 0.04775969\n",
      "[345,     1] loss: 0.04466816\n",
      "[346,     1] loss: 0.04389646\n",
      "[347,     1] loss: 0.03882897\n",
      "[348,     1] loss: 0.04351720\n",
      "[349,     1] loss: 0.02070679\n",
      "[350,     1] loss: 0.04381483\n",
      "[351,     1] loss: 0.04640667\n",
      "[352,     1] loss: 0.04701440\n",
      "[353,     1] loss: 0.03607788\n",
      "[354,     1] loss: 0.04925036\n",
      "[355,     1] loss: 0.03037708\n",
      "[356,     1] loss: 0.05790170\n",
      "[357,     1] loss: 0.04061067\n",
      "[358,     1] loss: 0.04540610\n",
      "[359,     1] loss: 0.02263885\n",
      "[360,     1] loss: 0.02469400\n",
      "[361,     1] loss: 0.05420065\n",
      "[362,     1] loss: 0.04893482\n",
      "[363,     1] loss: 0.04893708\n",
      "[364,     1] loss: 0.05692206\n",
      "[365,     1] loss: 0.04040261\n",
      "[366,     1] loss: 0.07153670\n",
      "[367,     1] loss: 0.05238933\n",
      "[368,     1] loss: 0.02843290\n",
      "[369,     1] loss: 0.04121386\n",
      "[370,     1] loss: 0.05117620\n",
      "[371,     1] loss: 0.03740326\n",
      "[372,     1] loss: 0.04147609\n",
      "[373,     1] loss: 0.03112062\n",
      "[374,     1] loss: 0.05061545\n",
      "[375,     1] loss: 0.03924306\n",
      "[376,     1] loss: 0.04760655\n",
      "[377,     1] loss: 0.03619104\n",
      "[378,     1] loss: 0.04552304\n",
      "[379,     1] loss: 0.04764609\n",
      "[380,     1] loss: 0.03905399\n",
      "[381,     1] loss: 0.03671228\n",
      "[382,     1] loss: 0.02544249\n",
      "[383,     1] loss: 0.04485849\n",
      "[384,     1] loss: 0.03619117\n",
      "[385,     1] loss: 0.01795810\n",
      "[386,     1] loss: 0.03624886\n",
      "[387,     1] loss: 0.04656023\n",
      "[388,     1] loss: 0.02375577\n",
      "[389,     1] loss: 0.03823032\n",
      "[390,     1] loss: 0.06242518\n",
      "[391,     1] loss: 0.04264845\n",
      "[392,     1] loss: 0.02361427\n",
      "[393,     1] loss: 0.05002698\n",
      "[394,     1] loss: 0.01570803\n",
      "[395,     1] loss: 0.02845367\n",
      "[396,     1] loss: 0.02781067\n",
      "[397,     1] loss: 0.04075157\n",
      "[398,     1] loss: 0.02701845\n",
      "[399,     1] loss: 0.04682846\n",
      "[400,     1] loss: 0.04055699\n",
      "[401,     1] loss: 0.03202017\n",
      "[402,     1] loss: 0.04976314\n",
      "[403,     1] loss: 0.05278515\n",
      "[404,     1] loss: 0.03961375\n",
      "[405,     1] loss: 0.05490065\n",
      "[406,     1] loss: 0.02547176\n",
      "[407,     1] loss: 0.03586280\n",
      "[408,     1] loss: 0.02841987\n",
      "[409,     1] loss: 0.05435617\n",
      "[410,     1] loss: 0.04919998\n",
      "[411,     1] loss: 0.05046879\n",
      "[412,     1] loss: 0.02826333\n",
      "[413,     1] loss: 0.03821330\n",
      "[414,     1] loss: 0.01892742\n",
      "[415,     1] loss: 0.02569066\n",
      "[416,     1] loss: 0.04023133\n",
      "[417,     1] loss: 0.04262073\n",
      "[418,     1] loss: 0.04154924\n",
      "[419,     1] loss: 0.04316130\n",
      "[420,     1] loss: 0.06221371\n",
      "[421,     1] loss: 0.02543746\n",
      "[422,     1] loss: 0.02043555\n",
      "[423,     1] loss: 0.04411447\n",
      "[424,     1] loss: 0.04689656\n",
      "[425,     1] loss: 0.05379524\n",
      "[426,     1] loss: 0.07161912\n",
      "[427,     1] loss: 0.03847777\n",
      "[428,     1] loss: 0.03997154\n",
      "[429,     1] loss: 0.04932243\n",
      "[430,     1] loss: 0.03812824\n",
      "[431,     1] loss: 0.04323901\n",
      "[432,     1] loss: 0.02809063\n",
      "[433,     1] loss: 0.05935808\n",
      "[434,     1] loss: 0.05401686\n",
      "[435,     1] loss: 0.05900656\n",
      "[436,     1] loss: 0.03408688\n",
      "[437,     1] loss: 0.03424240\n",
      "[438,     1] loss: 0.03443225\n",
      "[439,     1] loss: 0.05363393\n",
      "[440,     1] loss: 0.03527245\n",
      "[441,     1] loss: 0.04459479\n",
      "[442,     1] loss: 0.06504939\n",
      "[443,     1] loss: 0.05656179\n",
      "[444,     1] loss: 0.03211055\n",
      "[445,     1] loss: 0.03821375\n",
      "[446,     1] loss: 0.02068920\n",
      "[447,     1] loss: 0.02787849\n",
      "[448,     1] loss: 0.01094609\n",
      "[449,     1] loss: 0.03426185\n",
      "[450,     1] loss: 0.03878415\n",
      "[451,     1] loss: 0.04204727\n",
      "[452,     1] loss: 0.05072743\n",
      "[453,     1] loss: 0.02469310\n",
      "[454,     1] loss: 0.02926390\n",
      "[455,     1] loss: 0.04551027\n",
      "[456,     1] loss: 0.01889982\n",
      "[457,     1] loss: 0.07227038\n",
      "[458,     1] loss: 0.03168766\n",
      "[459,     1] loss: 0.02834382\n",
      "[460,     1] loss: 0.06839047\n",
      "[461,     1] loss: 0.03714675\n",
      "[462,     1] loss: 0.03517956\n",
      "[463,     1] loss: 0.06074380\n",
      "[464,     1] loss: 0.03421658\n",
      "[465,     1] loss: 0.02964098\n",
      "[466,     1] loss: 0.04878614\n",
      "[467,     1] loss: 0.08035596\n",
      "[468,     1] loss: 0.04077620\n",
      "[469,     1] loss: 0.06048749\n",
      "[470,     1] loss: 0.00942788\n",
      "[471,     1] loss: 0.01993236\n",
      "[472,     1] loss: 0.02778498\n",
      "[473,     1] loss: 0.04929665\n",
      "[474,     1] loss: 0.04997029\n",
      "[475,     1] loss: 0.07004355\n",
      "[476,     1] loss: 0.04845306\n",
      "[477,     1] loss: 0.03361120\n",
      "[478,     1] loss: 0.04073909\n",
      "[479,     1] loss: 0.03729543\n",
      "[480,     1] loss: 0.05593330\n",
      "[481,     1] loss: 0.03161045\n",
      "[482,     1] loss: 0.03570375\n",
      "[483,     1] loss: 0.06692491\n",
      "[484,     1] loss: 0.02618577\n",
      "[485,     1] loss: 0.04091150\n",
      "[486,     1] loss: 0.06070894\n",
      "[487,     1] loss: 0.03457296\n",
      "[488,     1] loss: 0.03460659\n",
      "[489,     1] loss: 0.03489265\n",
      "[490,     1] loss: 0.04301848\n",
      "[491,     1] loss: 0.05719762\n",
      "[492,     1] loss: 0.02036326\n",
      "[493,     1] loss: 0.02571157\n",
      "[494,     1] loss: 0.04545707\n",
      "[495,     1] loss: 0.03275244\n",
      "[496,     1] loss: 0.03340883\n",
      "[497,     1] loss: 0.02991833\n",
      "[498,     1] loss: 0.04085405\n",
      "[499,     1] loss: 0.04547504\n",
      "[500,     1] loss: 0.03335166\n",
      "[501,     1] loss: 0.03723247\n",
      "[502,     1] loss: 0.05439309\n",
      "[503,     1] loss: 0.04185304\n",
      "[504,     1] loss: 0.04081539\n",
      "[505,     1] loss: 0.03113319\n",
      "[506,     1] loss: 0.05506862\n",
      "[507,     1] loss: 0.04195888\n",
      "[508,     1] loss: 0.03335749\n",
      "[509,     1] loss: 0.03831814\n",
      "[510,     1] loss: 0.01729573\n",
      "[511,     1] loss: 0.06828348\n",
      "[512,     1] loss: 0.03473602\n",
      "[513,     1] loss: 0.04783645\n",
      "[514,     1] loss: 0.04217679\n",
      "[515,     1] loss: 0.05103080\n",
      "[516,     1] loss: 0.03979354\n",
      "[517,     1] loss: 0.03446084\n",
      "[518,     1] loss: 0.04099366\n",
      "[519,     1] loss: 0.03790884\n",
      "[520,     1] loss: 0.04154854\n",
      "[521,     1] loss: 0.04210798\n",
      "[522,     1] loss: 0.03525314\n",
      "[523,     1] loss: 0.03347508\n",
      "[524,     1] loss: 0.02468249\n",
      "[525,     1] loss: 0.03049266\n",
      "[526,     1] loss: 0.01757444\n",
      "[527,     1] loss: 0.03609776\n",
      "[528,     1] loss: 0.04250761\n",
      "[529,     1] loss: 0.04968293\n",
      "[530,     1] loss: 0.05293666\n",
      "[531,     1] loss: 0.03854894\n",
      "[532,     1] loss: 0.04284701\n",
      "[533,     1] loss: 0.05395781\n",
      "[534,     1] loss: 0.03822518\n",
      "[535,     1] loss: 0.02389025\n",
      "[536,     1] loss: 0.03491353\n",
      "[537,     1] loss: 0.02384481\n",
      "[538,     1] loss: 0.06639234\n",
      "[539,     1] loss: 0.02777765\n",
      "[540,     1] loss: 0.06875419\n",
      "[541,     1] loss: 0.06584472\n",
      "[542,     1] loss: 0.03512900\n",
      "[543,     1] loss: 0.05115143\n",
      "[544,     1] loss: 0.02686664\n",
      "[545,     1] loss: 0.03702917\n",
      "[546,     1] loss: 0.04283871\n",
      "[547,     1] loss: 0.03949611\n",
      "[548,     1] loss: 0.05096542\n",
      "[549,     1] loss: 0.04070190\n",
      "[550,     1] loss: 0.06135897\n",
      "[551,     1] loss: 0.04984996\n",
      "[552,     1] loss: 0.02165456\n",
      "[553,     1] loss: 0.05066092\n",
      "[554,     1] loss: 0.04650017\n",
      "[555,     1] loss: 0.04677618\n",
      "[556,     1] loss: 0.04739357\n",
      "[557,     1] loss: 0.05340522\n",
      "[558,     1] loss: 0.06957459\n",
      "[559,     1] loss: 0.02781218\n",
      "[560,     1] loss: 0.05913769\n",
      "[561,     1] loss: 0.05318301\n",
      "[562,     1] loss: 0.04637892\n",
      "[563,     1] loss: 0.05075026\n",
      "[564,     1] loss: 0.04872401\n",
      "[565,     1] loss: 0.04428931\n",
      "[566,     1] loss: 0.04102127\n",
      "[567,     1] loss: 0.03299225\n",
      "[568,     1] loss: 0.05243404\n",
      "[569,     1] loss: 0.01360375\n",
      "[570,     1] loss: 0.04120341\n",
      "[571,     1] loss: 0.02877186\n",
      "[572,     1] loss: 0.03659780\n",
      "[573,     1] loss: 0.04306684\n",
      "[574,     1] loss: 0.02619982\n",
      "[575,     1] loss: 0.05114178\n",
      "[576,     1] loss: 0.04178374\n",
      "[577,     1] loss: 0.04093334\n",
      "[578,     1] loss: 0.04965411\n",
      "[579,     1] loss: 0.03983227\n",
      "[580,     1] loss: 0.03366407\n",
      "[581,     1] loss: 0.01964963\n",
      "[582,     1] loss: 0.03321958\n",
      "[583,     1] loss: 0.03838909\n",
      "[584,     1] loss: 0.02326658\n",
      "[585,     1] loss: 0.05186182\n",
      "[586,     1] loss: 0.04849041\n",
      "[587,     1] loss: 0.05135890\n",
      "[588,     1] loss: 0.05261745\n",
      "[589,     1] loss: 0.04330912\n",
      "[590,     1] loss: 0.04017433\n",
      "[591,     1] loss: 0.04592226\n",
      "[592,     1] loss: 0.04186631\n",
      "[593,     1] loss: 0.03134665\n",
      "[594,     1] loss: 0.03138584\n",
      "[595,     1] loss: 0.02858257\n",
      "[596,     1] loss: 0.02797543\n",
      "[597,     1] loss: 0.07028238\n",
      "[598,     1] loss: 0.03130211\n",
      "[599,     1] loss: 0.03200160\n",
      "[600,     1] loss: 0.02499812\n",
      "[601,     1] loss: 0.04810904\n",
      "[602,     1] loss: 0.03909724\n",
      "[603,     1] loss: 0.05040167\n",
      "[604,     1] loss: 0.04804111\n",
      "[605,     1] loss: 0.04734064\n",
      "[606,     1] loss: 0.04451683\n",
      "[607,     1] loss: 0.05359931\n",
      "[608,     1] loss: 0.04183029\n",
      "[609,     1] loss: 0.06025156\n",
      "[610,     1] loss: 0.04307640\n",
      "[611,     1] loss: 0.04663137\n",
      "[612,     1] loss: 0.03594705\n",
      "[613,     1] loss: 0.04524895\n",
      "[614,     1] loss: 0.05631132\n",
      "[615,     1] loss: 0.03291371\n",
      "[616,     1] loss: 0.04810144\n",
      "[617,     1] loss: 0.04489214\n",
      "[618,     1] loss: 0.03443047\n",
      "[619,     1] loss: 0.04342727\n",
      "[620,     1] loss: 0.01741679\n",
      "[621,     1] loss: 0.02920079\n",
      "[622,     1] loss: 0.03442582\n",
      "[623,     1] loss: 0.04237253\n",
      "[624,     1] loss: 0.05476373\n",
      "[625,     1] loss: 0.04146569\n",
      "[626,     1] loss: 0.04004001\n",
      "[627,     1] loss: 0.03972726\n",
      "[628,     1] loss: 0.03881528\n",
      "[629,     1] loss: 0.03438760\n",
      "[630,     1] loss: 0.04250387\n",
      "[631,     1] loss: 0.03234557\n",
      "[632,     1] loss: 0.02638084\n",
      "[633,     1] loss: 0.02000869\n",
      "[634,     1] loss: 0.04511721\n",
      "[635,     1] loss: 0.03517637\n",
      "[636,     1] loss: 0.03591597\n",
      "[637,     1] loss: 0.05017455\n",
      "[638,     1] loss: 0.03222360\n",
      "[639,     1] loss: 0.06093695\n",
      "[640,     1] loss: 0.04187065\n",
      "[641,     1] loss: 0.04696786\n",
      "[642,     1] loss: 0.05650247\n",
      "[643,     1] loss: 0.03610953\n",
      "[644,     1] loss: 0.07222831\n",
      "[645,     1] loss: 0.05632818\n",
      "[646,     1] loss: 0.04862090\n",
      "[647,     1] loss: 0.02497796\n",
      "[648,     1] loss: 0.02619721\n",
      "[649,     1] loss: 0.04918229\n",
      "[650,     1] loss: 0.02447970\n",
      "[651,     1] loss: 0.03039889\n",
      "[652,     1] loss: 0.03056269\n",
      "[653,     1] loss: 0.01186875\n",
      "[654,     1] loss: 0.03228057\n",
      "[655,     1] loss: 0.03194927\n",
      "[656,     1] loss: 0.05589892\n",
      "[657,     1] loss: 0.02080331\n",
      "[658,     1] loss: 0.03959059\n",
      "[659,     1] loss: 0.03873809\n",
      "[660,     1] loss: 0.04144045\n",
      "[661,     1] loss: 0.06346887\n",
      "[662,     1] loss: 0.03621037\n",
      "[663,     1] loss: 0.04828985\n",
      "[664,     1] loss: 0.02338466\n",
      "[665,     1] loss: 0.05051368\n",
      "[666,     1] loss: 0.03918424\n",
      "[667,     1] loss: 0.05300703\n",
      "[668,     1] loss: 0.04443738\n",
      "[669,     1] loss: 0.02524966\n",
      "[670,     1] loss: 0.04631815\n",
      "[671,     1] loss: 0.05423908\n",
      "[672,     1] loss: 0.05380969\n",
      "[673,     1] loss: 0.05469466\n",
      "[674,     1] loss: 0.04103937\n",
      "[675,     1] loss: 0.03582710\n",
      "[676,     1] loss: 0.03615113\n",
      "[677,     1] loss: 0.03504820\n",
      "[678,     1] loss: 0.03065243\n",
      "[679,     1] loss: 0.03069271\n",
      "[680,     1] loss: 0.04214129\n",
      "[681,     1] loss: 0.03485931\n",
      "[682,     1] loss: 0.02816982\n",
      "[683,     1] loss: 0.03569362\n",
      "[684,     1] loss: 0.05349918\n",
      "[685,     1] loss: 0.03719007\n",
      "[686,     1] loss: 0.07226539\n",
      "[687,     1] loss: 0.04674668\n",
      "[688,     1] loss: 0.03436058\n",
      "[689,     1] loss: 0.03368266\n",
      "[690,     1] loss: 0.04429837\n",
      "[691,     1] loss: 0.04682510\n",
      "[692,     1] loss: 0.03910036\n",
      "[693,     1] loss: 0.02675303\n",
      "[694,     1] loss: 0.03848114\n",
      "[695,     1] loss: 0.04360770\n",
      "[696,     1] loss: 0.04165410\n",
      "[697,     1] loss: 0.05069683\n",
      "[698,     1] loss: 0.06290804\n",
      "[699,     1] loss: 0.01989506\n",
      "[700,     1] loss: 0.04141036\n",
      "[701,     1] loss: 0.04362535\n",
      "[702,     1] loss: 0.04043584\n",
      "[703,     1] loss: 0.04086270\n",
      "[704,     1] loss: 0.04474665\n",
      "[705,     1] loss: 0.02185341\n",
      "[706,     1] loss: 0.04154247\n",
      "[707,     1] loss: 0.04559161\n",
      "[708,     1] loss: 0.03612771\n",
      "[709,     1] loss: 0.02674924\n",
      "[710,     1] loss: 0.03318042\n",
      "[711,     1] loss: 0.03633545\n",
      "[712,     1] loss: 0.04292919\n",
      "[713,     1] loss: 0.05630974\n",
      "[714,     1] loss: 0.04431688\n",
      "[715,     1] loss: 0.04375303\n",
      "[716,     1] loss: 0.05779725\n",
      "[717,     1] loss: 0.05492358\n",
      "[718,     1] loss: 0.02904920\n",
      "[719,     1] loss: 0.03502531\n",
      "[720,     1] loss: 0.05439318\n",
      "[721,     1] loss: 0.03569246\n",
      "[722,     1] loss: 0.05162073\n",
      "[723,     1] loss: 0.03701005\n",
      "[724,     1] loss: 0.03179961\n",
      "[725,     1] loss: 0.07319324\n",
      "[726,     1] loss: 0.05030483\n",
      "[727,     1] loss: 0.06715436\n",
      "[728,     1] loss: 0.04804366\n",
      "[729,     1] loss: 0.04957307\n",
      "[730,     1] loss: 0.02672981\n",
      "[731,     1] loss: 0.03609683\n",
      "[732,     1] loss: 0.04869223\n",
      "[733,     1] loss: 0.02663043\n",
      "[734,     1] loss: 0.05146955\n",
      "[735,     1] loss: 0.02737415\n",
      "[736,     1] loss: 0.05136744\n",
      "[737,     1] loss: 0.05275185\n",
      "[738,     1] loss: 0.04985475\n",
      "[739,     1] loss: 0.06360679\n",
      "[740,     1] loss: 0.03910151\n",
      "[741,     1] loss: 0.02813073\n",
      "[742,     1] loss: 0.05824450\n",
      "[743,     1] loss: 0.04806160\n",
      "[744,     1] loss: 0.05052911\n",
      "[745,     1] loss: 0.03947107\n",
      "[746,     1] loss: 0.03909365\n",
      "[747,     1] loss: 0.04948328\n",
      "[748,     1] loss: 0.01781016\n",
      "[749,     1] loss: 0.03814882\n",
      "[750,     1] loss: 0.03595461\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29e770eb0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = True\n",
    "num_epochs = 750\n",
    "batch_size = 5\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(policy.parameters()), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(trajs)))\n",
    "\n",
    "num_batches = len(idxs) // batch_size\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    np.random.shuffle(idxs)\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_idx = np.random.randint(len(trajs), size=(batch_size,)) # Indices of traj\n",
    "        t_idx_pertraj = np.random.randint(1, size=(batch_size,)) # Indices of timesteps in traj\n",
    "        if mask:\n",
    "            t_states = np.concatenate([trajs[c_idx]['mask_obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "\n",
    "        else:\n",
    "            t_states = np.concatenate([trajs[c_idx]['obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_goals = np.concatenate([trajs[c_idx]['goals'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_actions = np.concatenate([trajs[c_idx]['acts'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "   \n",
    "        t_states = torch.Tensor(t_states).float().to(device)\n",
    "        t_goals = torch.Tensor(t_goals).float().to(device)\n",
    "        t_actions = torch.Tensor(t_actions).float().to(device)\n",
    "        \n",
    "        #a_preds = policy(t_states, t_goals)\n",
    "        a_preds = policy(t_states)\n",
    "        loss = torch.mean(torch.linalg.norm(a_preds - t_actions, dim=-1)) # supervised learning loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "torch.save(policy, 'policy_gcbc.pt')\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee1bd52a-f3e5-41d7-b327-cb9bf03e20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_goal = 'sweep the block while avoiding the line'\n",
    "lang_embed = lang_model.encode(lang_goal)\n",
    "phi_hat = {\n",
    "    'block': ['red'],\n",
    "}\n",
    "mask = True\n",
    "\n",
    "#task_name = 'sweep_without_touching'\n",
    "#task_kwargs = {'constraint': True,\n",
    "#               'dragged_obj_loc': [4],\n",
    "#               'possible_base_obj': ['three-sided rectangle'],\n",
    "#               'possible_base_obj_texture': ['blue'],\n",
    "#               'possible_dragged_obj': ['small block'],\n",
    "#               'possible_dragged_obj_texture': ['granite'],\n",
    "#               'possible_constraint_obj': ['line'],\n",
    "#               'possible_constraint_obj_texture': ['tiger']}\n",
    "task_kwargs = { \n",
    "    'num_dragged_obj': 1,\n",
    "    'num_base_obj': 1,\n",
    "    'num_other_obj': 2,\n",
    "    'dragged_obj_loc': [1],\n",
    "    'base_obj_loc': [4],\n",
    "    'third_obj_loc' : [3],\n",
    "    'fourth_obj_loc' : [2],\n",
    "    'possible_dragged_obj': ['tomato'],\n",
    "    'possible_dragged_obj_texture': ['red'],\n",
    "    'possible_base_obj': ['square'],\n",
    "    'possible_base_obj_texture': ['blue'],\n",
    "    'possible_third_obj': ['tomato'],\n",
    "    'possible_third_obj_texture': ['green'],\n",
    "    'possible_fourth_obj': ['star'],\n",
    "    'possible_fourth_obj_texture': ['yellow']\n",
    "}\n",
    "record_cfg = {'save_video': True,\n",
    "     'save_video_path': './rollouts_gcbc/',\n",
    "     'view': 'front',\n",
    "     'fps': 18,\n",
    "     'video_height': 320,\n",
    "     'video_width': 368}\n",
    "# record_gui=True, display_debug_window=True, hide_arm_rgb=False\n",
    "env = vima_bench.make(task_name=task_name,task_kwargs=task_kwargs,hide_arm_rgb=False,display_debug_window=False,record_cfg=record_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10160fc2-8e9d-4d65-8517-3421c5fae5d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "oracle = True\n",
    "\n",
    "if oracle:\n",
    "    task = env.task\n",
    "    oracle_fn = task.oracle(env)\n",
    "else:\n",
    "    policy = torch.load('policy_gcbc.pt')\n",
    "    policy.eval()\n",
    "\n",
    "num_test_trajs = 1\n",
    "video = True\n",
    "\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.ylim(0.3, 0.7)\n",
    "\n",
    "successes = []\n",
    "\n",
    "rollouts = {'actions': [], 'action_starts': [],'action_ends': [], 'true_starts': [], 'true_ends': []}\n",
    "\n",
    "for i in tqdm(range(num_test_trajs)):\n",
    "    os.makedirs('rollouts_gcbc/' + str(i), exist_ok=True)\n",
    "    obs = env.reset()\n",
    "    obj_type = env.meta_info['obj_id_to_info'][6]['obj_name']\n",
    "    goal_embed = lang_model.encode(obj_type)\n",
    "    \n",
    "    if video:\n",
    "        video_name = str(i)\n",
    "        env.start_rec(video_name)\n",
    "    for step in range(1):\n",
    "        if oracle:\n",
    "            oracle_action = oracle_fn.act(obs)\n",
    "            # clip action\n",
    "            oracle_action = {\n",
    "                k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "                for k, v in oracle_action.items()\n",
    "            }\n",
    "            obs, _, done, info = env.step(action=oracle_action, skip_oracle=False)\n",
    "        \n",
    "        else:\n",
    "            # constructs s_hat from phi_hat\n",
    "            segm = obs['segm']['top']\n",
    "            s_hat = process_segm(segm, phi_hat, env.meta_info['obj_id_to_info'])\n",
    "            im = Image.fromarray(s_hat.astype(np.uint8))\n",
    "            im.save('rollouts_gcbc/'+str(i)+\"/\"+str(step)+'_mask.jpg')\n",
    "            \n",
    "            # saves rgb image as well\n",
    "            top_obs = obs['rgb']['top']\n",
    "            top_obs = process_obs(top_obs)\n",
    "            im = Image.fromarray(top_obs)\n",
    "            im.save('rollouts_gcbc/'+str(i)+\"/\"+str(step)+'.jpg')\n",
    "            \n",
    "            # uses either s_hat or true obs\n",
    "            state = s_hat if mask else top_obs\n",
    "            \n",
    "            state = torch.Tensor(state[None]).to(device)\n",
    "            goal = torch.Tensor(lang_embed[None]).to(device)\n",
    "            #action = policy(state,goal).cpu().detach().numpy()[0]\n",
    "            action = policy(state).cpu().detach().numpy()[0]\n",
    "            \n",
    "            rollouts['actions'].append(action)\n",
    "            rollouts['action_starts'].append(action[0:2].copy())\n",
    "            rollouts['action_ends'].append(action[6:8].copy())\n",
    "            obs, _, done, info = env.step(action=reconstruct_act(action), skip_oracle=False)\n",
    "        \n",
    "        if done:\n",
    "            successes.append(1)\n",
    "        else:\n",
    "            successes.append(0)\n",
    "            \n",
    "    if video:\n",
    "        env.end_rec()\n",
    "    \n",
    "    # constructs s_hat from phi_hat\n",
    "    segm = obs['segm']['top']\n",
    "    s_hat = process_segm(segm, phi_hat, env.meta_info['obj_id_to_info'])\n",
    "    im = Image.fromarray(s_hat.astype(np.uint8))\n",
    "    im.save('rollouts_gcbc/'+str(i)+\"/\"+str(step+1)+'_mask.jpg')\n",
    "            \n",
    "    # saves rgb image as well\n",
    "    top_obs = obs['rgb']['top']\n",
    "    top_obs = process_obs(top_obs)\n",
    "    im = Image.fromarray(top_obs)\n",
    "    im.save('rollouts_gcbc/'+str(i)+\"/\"+str(step+1)+'.jpg')\n",
    "\n",
    "env.close()\n",
    "print(sum(successes)/len(successes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6470c4-8380-4dfa-989e-2049c02cd00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
