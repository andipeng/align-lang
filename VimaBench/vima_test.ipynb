{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77db741a-d9b8-4cd4-acdd-c2477e5e6a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andipeng/miniforge3/envs/align-lang/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "pybullet build time: Apr 20 2023 11:39:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 17 tasks loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import io\n",
    "import json\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import distributions as pyd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode - o\n",
    "\n",
    "import vima_bench\n",
    "from vima_bench import PARTITION_TO_SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0f9ffc-1863-416a-887e-44f008b71c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "                \n",
    "# helper mlp init function\n",
    "def mlp(input_dim, output_dim, hidden_dim, hidden_depth, output_mod=None):\n",
    "    if hidden_depth == 0:\n",
    "        mods = [nn.Linear(input_dim, output_dim)]\n",
    "    else:\n",
    "        mods = [nn.Linear(input_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        for i in range(hidden_depth - 1):\n",
    "            mods += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        mods.append(nn.Linear(hidden_dim, output_dim))\n",
    "    if output_mod is not None:\n",
    "        mods.append(output_mod)\n",
    "    trunk = nn.Sequential(*mods)\n",
    "    return trunk\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.size(0), -1)\n",
    "\n",
    "# MLP policy\n",
    "class CNNPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, action_dim, hidden_size, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.cnntrunk = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,72)=>(b_size,32,8,17)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,17)=>(b_size,64,3,7)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(), #(b_size,64,3,7)=>(b_size,32,1,5)=>(b_size,32*1*5)\n",
    "            nn.Linear(32*1*5, action_dim)#, nn.LeakyReLU(inplace=True), nn.BatchNorm1d(32), #(b_size,32*1*5)=>(b_size,action_dim)\n",
    "        )\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = state/255.0 # process image + switch channels\n",
    "        state = state.permute(0,3,1,2)\n",
    "        \n",
    "        pred = self.cnntrunk(state)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07cbd67-71e4-4c60-8662-070077913cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsize_obs(obs):\n",
    "    cv2.imwrite('temp.jpg', obs)\n",
    "    img = cv2.imread('temp.jpg')\n",
    "    downsized_obs = cv2.resize(img, dsize=(72, 36), interpolation=cv2.INTER_CUBIC)\n",
    "    return downsized_obs\n",
    "\n",
    "def flatten_act(action):\n",
    "    return np.concatenate(list(action.values())).ravel()\n",
    "\n",
    "# reconstructs actions for simulator\n",
    "def reconstruct_act(action):\n",
    "    reconst_action = {}\n",
    "    reconst_action['pose0_position'] = np.array(action[0:2])\n",
    "    reconst_action['pose0_rotation'] = np.array(action[2:6])\n",
    "    reconst_action['pose1_position'] = np.array(action[6:8])\n",
    "    reconst_action['pose1_rotation'] = np.array(action[8:12])\n",
    "    reconst_action = {\n",
    "        k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "        for k, v in reconst_action.items()\n",
    "    }\n",
    "    return reconst_action\n",
    "\n",
    "def remove_obj(segm, obs, remove_obj):\n",
    "    #if remove_obj == 'arm':\n",
    "    #    segm = (segm == 2).astype(int)\n",
    "    if remove_obj == 'base':\n",
    "        segm = (segm == 5).astype(int)\n",
    "    elif remove_obj == 'dragged':\n",
    "        segm = (segm == 6).astype(int)\n",
    "    elif remove_obj == 'distractor':\n",
    "        segm = (segm == 7).astype(int)\n",
    "    segm = np.atleast_3d(segm)\n",
    "    \n",
    "    for height in range(128):\n",
    "        for width in range(256):\n",
    "            if segm[height, width] == 1:\n",
    "                obs[height, width] = 47\n",
    "    return obs\n",
    "\n",
    "def compare_actions(actions, gt_action):\n",
    "    comparisons = []\n",
    "    for action in actions:\n",
    "        comparisons.append(np.linalg.norm(gt_action - action[[0,1,6,7]],ord=2))\n",
    "    return comparisons\n",
    "\n",
    "# generates random trajs within specified constraints\n",
    "def gen_trajs(env, num_trajs, task_name, task_kwargs):\n",
    "    trajs = []\n",
    "    task = env.task\n",
    "    oracle_fn = task.oracle(env)\n",
    "    for traj in tqdm(range(num_trajs)):\n",
    "        traj = {'obs': [],'acts': [], 'meta': []}\n",
    "        obs = env.reset()\n",
    "        traj['meta'] = env.meta_info\n",
    "        for step in range(1):\n",
    "            top_obs = obs['rgb']['top'] # extracts top down view only\n",
    "            top_obs = np.rollaxis(top_obs,0,3)\n",
    "            traj['obs'].append(downsize_obs(top_obs.copy()))\n",
    "            # prompt, prompt_assets = env.prompt, env.prompt_assets\n",
    "            oracle_action = oracle_fn.act(obs)\n",
    "            # clip action\n",
    "            oracle_action = {\n",
    "                k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "                for k, v in oracle_action.items()\n",
    "            }\n",
    "            traj['acts'].append(flatten_act(oracle_action))\n",
    "            obs, _, done, info = env.step(action=oracle_action, skip_oracle=False)\n",
    "        traj['obs'] = np.array(traj['obs'])\n",
    "        traj['acts'] = np.array(traj['acts'])\n",
    "        traj['meta'] = np.array(traj['meta'])\n",
    "        trajs.append(traj)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccfc2f6-2659-4640-b9d6-0a7546455ef9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_name = 'visual_manipulation'\n",
    "#task_kwargs=PARTITION_TO_SPECS[\"train\"][task_name]\n",
    "task_kwargs = { 'num_dragged_obj': 1,\n",
    "     'num_base_obj': 1,\n",
    "     'num_other_obj': 0,\n",
    "     'dragged_obj_loc': [3],\n",
    "     'base_obj_loc': [1],\n",
    "     'third_obj_loc' : [2],\n",
    "     'fourth_obj_loc' : [4],\n",
    "     'possible_dragged_obj': ['flower'],\n",
    "     'possible_dragged_obj_texture': ['green'],\n",
    "     'possible_base_obj': ['bowl'],\n",
    "     'possible_base_obj_texture': ['yellow'],\n",
    "     'possible_third_obj': ['letter A'],\n",
    "     'possible_third_obj_texture': ['purple'],\n",
    "     'possible_fourth_obj': ['pentagon'],\n",
    "    'possible_fourth_obj_texture': ['blue']}\n",
    "#record_gui=True, display_debug_window=True, hide_arm_rgb=False\n",
    "env = vima_bench.make(task_name=task_name,task_kwargs=task_kwargs,hide_arm_rgb=False)\n",
    "\n",
    "num_trajs = 5\n",
    "trajs = gen_trajs(env=env, num_trajs=num_trajs, task_name=task_name, task_kwargs=task_kwargs)\n",
    "pickle.dump(trajs, open('trajs.pkl', 'wb'))\n",
    "env.close()\n",
    "#obs = env.reset()\n",
    "#top_obs = obs['rgb']['top']\n",
    "#top_obs = np.rollaxis(top_obs,0,3)\n",
    "#plt.imshow(top_obs)\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95620041-1b7d-47f7-a043-eed9b05e824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajs = pickle.load(open('trajs.pkl','rb'))\n",
    "plt.imshow(trajs[0]['obs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b88c2-3372-4b12-b64e-3b7d4cf43f4d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_tasks = len(trajs)\n",
    "\n",
    "act_size = trajs[0]['acts'][0].shape[0]\n",
    "hidden_size = 100\n",
    "\n",
    "policy = CNNPolicy(act_size, hidden_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde3ee5-ce6a-41eb-ac85-860781776e8f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "batch_size = 10\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(policy.parameters()))\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(trajs)))\n",
    "\n",
    "num_batches = len(idxs) // batch_size\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    np.random.shuffle(idxs)\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_idx = np.random.randint(len(trajs), size=(batch_size,)) # Indices of traj\n",
    "        t_idx_pertraj = np.random.randint(1, size=(batch_size,)) # Indices of timesteps in traj\n",
    "        t_states = np.concatenate([trajs[c_idx]['obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_actions = np.concatenate([trajs[c_idx]['acts'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "   \n",
    "        t_states = torch.Tensor(t_states).float().to(device)\n",
    "        t_actions = torch.Tensor(t_actions).float().to(device)\n",
    "        \n",
    "        a_preds = policy(t_states)[0]\n",
    "        loss = torch.mean(torch.linalg.norm(a_preds - t_actions, dim=-1)) # supervised learning loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "torch.save(policy, 'policy.pt')\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee1bd52a-f3e5-41d7-b327-cb9bf03e20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"rearrange\"\n",
    "#task_kwargs = { 'num_dragged_obj': 1,\n",
    "#     'num_base_obj': 1,\n",
    "#     'num_other_obj': 0,\n",
    "#     'dragged_obj_loc': [3],\n",
    "#     'base_obj_loc': [1],\n",
    "#     'third_obj_loc' : [2],\n",
    "#     'fourth_obj_loc' : [4],\n",
    "#     'possible_dragged_obj': ['flower'],\n",
    "#     'possible_dragged_obj_texture': ['green'],\n",
    "#     'possible_base_obj': ['bowl'],\n",
    "#     'possible_base_obj_texture': ['yellow'],\n",
    "#     'possible_third_obj': ['letter A'],\n",
    "#     'possible_third_obj_texture': ['purple'],\n",
    "#     'possible_fourth_obj': ['pentagon'],\n",
    "#     'possible_fourth_obj_texture': ['blue']}\n",
    "#task_kwargs = {'possible_dragged_obj': ['pentagon','flower']}\n",
    "record_cfg = {'save_video': True,\n",
    "     'save_video_path': './rollouts/',\n",
    "     'view': 'front',\n",
    "     'fps': 20,\n",
    "     'video_height': 640,\n",
    "     'video_width': 720}\n",
    "# record_gui=True, display_debug_window=True, hide_arm_rgb=False\n",
    "env = vima_bench.make(task_name=task_name,task_kwargs=None,hide_arm_rgb=False,record_cfg=record_cfg)\n",
    "#obs = env.reset()\n",
    "#segm = obs['segm']['top']\n",
    "#top_obs = obs['rgb']['top']\n",
    "#top_obs = np.rollaxis(top_obs,0,3)\n",
    "#plt.imshow(remove_obj(segm, top_obs, 'dragged'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10160fc2-8e9d-4d65-8517-3421c5fae5d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 repeated sampling random target of objects\n"
     ]
    }
   ],
   "source": [
    "oracle = True\n",
    "\n",
    "if oracle:\n",
    "    task = env.task\n",
    "    oracle_fn = task.oracle(env)\n",
    "else:\n",
    "    policy = torch.load('policy.pt')\n",
    "    policy.eval()\n",
    "\n",
    "obj_to_remove = None#['base']\n",
    "num_test_trajs = 1\n",
    "video = True\n",
    "\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.ylim(0.3, 0.7)\n",
    "\n",
    "successes = []\n",
    "\n",
    "rollouts = {'actions': [], 'action_starts': [],'action_ends': [], 'true_starts': [], 'true_ends': []}\n",
    "\n",
    "for i in tqdm(range(num_test_trajs)):\n",
    "    os.makedirs('rollouts/' + str(i), exist_ok=True)\n",
    "    obs = env.reset()\n",
    "    #rollouts['true_starts'].append(env.task.dragged_pose[0])\n",
    "    #rollouts['true_ends'].append(env.task.base_pose[0])\n",
    "    \n",
    "    if video:\n",
    "        video_name = str(i)\n",
    "        env.start_rec(video_name)\n",
    "    for step in range(1):\n",
    "        if oracle:\n",
    "            oracle_action = oracle_fn.act(obs)\n",
    "            # clip action\n",
    "            oracle_action = {\n",
    "                k: np.clip(v, env.action_space[k].low, env.action_space[k].high)\n",
    "                for k, v in oracle_action.items()\n",
    "            }\n",
    "            obs, _, done, info = env.step(action=oracle_action, skip_oracle=False)\n",
    "        \n",
    "        else:\n",
    "            segm = obs['segm']['top']\n",
    "            top_obs = obs['rgb']['top']\n",
    "            top_obs = np.rollaxis(top_obs,0,3)\n",
    "\n",
    "            if obj_to_remove is not None:\n",
    "                obj_removed = random.choice(obj_to_remove)\n",
    "                segm = obs['segm']['top']\n",
    "                top_obs = remove_obj(segm, top_obs, obj_removed)\n",
    "            first_obs = top_obs.copy()\n",
    "\n",
    "            im = Image.fromarray(top_obs)\n",
    "            im.save('rollouts/'+str(i)+\"/\"+str(step)+'.jpg')\n",
    "            top_obs = downsize_obs(top_obs)\n",
    "            state = torch.Tensor(top_obs[None]).to(device)\n",
    "            action = policy(state).cpu().detach().numpy()[0]\n",
    "            \n",
    "            rollouts['actions'].append(action)\n",
    "            rollouts['action_starts'].append(action[0:2].copy())\n",
    "            rollouts['action_ends'].append(action[6:8].copy())\n",
    "            obs, _, done, info = env.step(action=reconstruct_act(action), skip_oracle=False)\n",
    "        \n",
    "        if done:\n",
    "            successes.append(1)\n",
    "        else:\n",
    "            successes.append(0)\n",
    "            \n",
    "    if video:\n",
    "        env.end_rec()\n",
    "        \n",
    "    top_obs = obs['rgb']['top']\n",
    "    top_obs = np.rollaxis(top_obs,0,3)\n",
    "    \n",
    "    if obj_to_remove is not None:\n",
    "        segm = obs['segm']['top']\n",
    "        top_obs = remove_obj(segm, top_obs, obj_removed)\n",
    "        \n",
    "    im = Image.fromarray(top_obs)\n",
    "    im.save('rollouts/'+str(i)+\"/\"+str(step+1)+'.jpg')\n",
    "\n",
    "env.close()\n",
    "\n",
    "if not oracle:\n",
    "    plt.scatter(np.array(rollouts['true_starts'])[:, 1], np.array(rollouts['true_starts'])[:, 0], marker='o', color='g', label='gt starts')\n",
    "    plt.scatter(np.array(rollouts['true_ends'])[:, 1], np.array(rollouts['true_ends'])[:, 0], marker='x', color='g', label='gt ends')\n",
    "    plt.scatter(np.array(rollouts['action_starts'])[:, 1], np.array(rollouts['action_starts'])[:, 0], marker='o', color='r', label='rollout starts')\n",
    "    plt.scatter(np.array(rollouts['action_ends'])[:, 1], np.array(rollouts['action_ends'])[:, 0], marker='x', color='r', label='rollout ends')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend()\n",
    "print(sum(successes)/len(successes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae59c2-c87f-4e2f-a91b-e99144f02302",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(first_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d61716-d37b-4296-b93d-39bd26c97ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(top_obs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
